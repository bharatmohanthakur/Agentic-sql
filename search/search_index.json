{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#agentic-sql","title":"Agentic SQL","text":"<p>Pure LLM Intelligence for Text-to-SQL</p> <p> </p> <p>Get Started View on GitHub</p>"},{"location":"#what-is-agentic-sql","title":"What is Agentic SQL?","text":"<p>Agentic SQL is a truly intelligent Text-to-SQL framework that:</p> <ul> <li>Works on ANY database without configuration</li> <li>Has ZERO hardcoded rules - everything is learned</li> <li>Auto-discovers schema and SQL dialect</li> <li>Self-heals when errors occur</li> <li>Learns from every interaction</li> </ul> <pre><code># That's all you need\nagent = MetaAgent(llm_client=llm)\nawait agent.connect(db_executor=db.execute)\nresult = await agent.query(\"How many orders last month?\")\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#material-magnify-auto-discovery","title":":material-magnify: Auto-Discovery","text":"<p>Automatically detects SQL dialect, discovers schema, identifies relationships, and learns naming conventions.</p>"},{"location":"#material-brain-auto-learning","title":":material-brain: Auto-Learning","text":"<p>Self-trains on your database. Question count dynamically calculated based on schema complexity.</p>"},{"location":"#material-wrench-self-healing","title":":material-wrench: Self-Healing","text":"<p>Analyzes errors, searches for correct names, learns corrections, and retries automatically.</p>"},{"location":"#material-database-multi-database","title":":material-database: Multi-Database","text":"<p>Works with MS SQL Server, PostgreSQL, MySQL, SQLite, and more. Same API for all.</p>"},{"location":"#material-memory-persistent-memory","title":":material-memory: Persistent Memory","text":"<p>Hybrid memory with Graph + Vector + SQL stores. Never makes the same mistake twice.</p>"},{"location":"#material-robot-multi-agent","title":":material-robot: Multi-Agent","text":"<p>Build complex workflows with SQL, Analyst, and Validator agents.</p>"},{"location":"#quick-example","title":"Quick Example","text":"Basic QueryWith Auto-LearningAPI Server <pre><code>import asyncio\nfrom src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\n\nasync def main():\n    # Setup LLM\n    llm = AzureOpenAIClient(AzureOpenAIConfig(\n        api_key=\"your-key\",\n        azure_endpoint=\"https://your-endpoint.openai.azure.com\",\n        azure_deployment=\"gpt-4o\",\n    ))\n\n    # Create agent\n    agent = MetaAgent(llm_client=llm)\n\n    # Connect (auto-discovers everything!)\n    await agent.connect(db_executor=db.execute)\n\n    # Query naturally\n    result = await agent.query(\"Show top 10 customers by revenue\")\n\n    print(f\"SQL: {result['sql']}\")\n    print(f\"Data: {result['data']}\")\n\nasyncio.run(main())\n</code></pre> <pre><code># Connect to database\nawait agent.connect(db_executor=db.execute)\n\n# Auto-train (questions based on schema complexity)\nresults = await agent.auto_learn(intensity=\"medium\")\n\nprint(f\"Domain: {results['domain']}\")\nprint(f\"Success rate: {results['success_rate']*100:.0f}%\")\n\n# Now queries use learned knowledge\nresult = await agent.query(\"Which products are low in stock?\")\n</code></pre> <pre><code>from src.api.server import create_app, APIConfig\n\napp = create_app(\n    config=APIConfig(host=\"0.0.0.0\", port=8000),\n    sql_agent=agent,\n)\n\n# Run: uvicorn main:app\n</code></pre> <pre><code>curl -X POST http://localhost:8000/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"question\": \"How many users?\"}'\n</code></pre>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph API[\"API Layer\"]\n        FastAPI[FastAPI + SSE]\n    end\n\n    subgraph Agent[\"Meta Agent\"]\n        Think[THINK]\n        Research[RESEARCH]\n        Design[DESIGN]\n        Execute[EXECUTE]\n        Learn[LEARN]\n        Think --&gt; Research --&gt; Design --&gt; Execute --&gt; Learn\n    end\n\n    subgraph Memory[\"Memory Manager\"]\n        Graph[Graph Store]\n        Vector[Vector Store]\n        SQL[SQL Store]\n    end\n\n    subgraph DB[\"Database Adapters\"]\n        MSSQL[MS SQL]\n        PG[PostgreSQL]\n        MySQL[MySQL]\n        SQLite[SQLite]\n    end\n\n    FastAPI --&gt; Agent\n    Agent --&gt; Memory\n    Agent --&gt; DB</code></pre>"},{"location":"#supported-databases","title":"Supported Databases","text":"Database Status Auto-Detected Features MS SQL Server :material-check-circle:{ .status-ready } Ready TOP, GETDATE, T-SQL PostgreSQL :material-check-circle:{ .status-ready } Ready LIMIT, NOW(), PL/pgSQL MySQL :material-check-circle:{ .status-ready } Ready LIMIT, backticks SQLite :material-check-circle:{ .status-ready } Ready LIMIT, datetime Snowflake :material-clock:{ .status-coming } Coming Warehouse syntax BigQuery :material-clock:{ .status-coming } Coming Standard SQL"},{"location":"#test-results","title":"Test Results","text":"Test Category Queries Success Rate Simple Queries 3 100% Date Queries 4 100% Aggregations 3 100% Complex Joins 3 100% Window Functions 3 100% Total 23 100% <p>Get Started :material-arrow-right:</p>"},{"location":"agents/","title":"Multi-Agent System","text":"<p>Build complex workflows with multiple agents.</p>"},{"location":"agents/#available-agents","title":"Available Agents","text":"Agent Purpose SQL Agent Text-to-SQL conversion Analyst Agent Result analysis Validator Agent Security validation"},{"location":"agents/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    O[Orchestrator]\n    O --&gt; SQL[SQL Agent]\n    O --&gt; A[Analyst Agent]\n    O --&gt; V[Validator Agent]</code></pre>"},{"location":"agents/#quick-start","title":"Quick Start","text":"<pre><code>from src.core.orchestrator import AgentOrchestrator\n\norchestrator = AgentOrchestrator()\norchestrator.register_agent(\"sql\", sql_agent)\norchestrator.register_agent(\"analyst\", analyst_agent)\n</code></pre>"},{"location":"agents/sql-agent/","title":"SQL Agent","text":"<p>Converts natural language to SQL using ReAct pattern.</p>"},{"location":"agents/sql-agent/#overview","title":"Overview","text":"<p>The SQL Agent implements:</p> <ul> <li>ReAct - Reasoning + Acting loop</li> <li>Reflection - Self-correction</li> <li>Tool Use - Database execution</li> </ul>"},{"location":"agents/sql-agent/#configuration","title":"Configuration","text":"<pre><code>from src.agents.sql_agent import SQLAgent, SQLAgentConfig\n\nagent = SQLAgent(\n    config=SQLAgentConfig(\n        name=\"sql_agent\",\n        max_sql_retries=3,\n        enable_query_validation=True,\n        block_destructive_queries=True,\n    ),\n    llm_client=llm,\n    db_executor=db.execute,\n)\n</code></pre>"},{"location":"agents/sql-agent/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>max_sql_retries</code> <code>int</code> <code>3</code> Max retry attempts <code>enable_query_validation</code> <code>bool</code> <code>True</code> Validate SQL <code>block_destructive_queries</code> <code>bool</code> <code>True</code> Block DROP/DELETE"},{"location":"agents/workflows/","title":"Workflows","text":"<p>Build complex multi-agent workflows.</p>"},{"location":"agents/workflows/#pipeline-builder","title":"Pipeline Builder","text":"<pre><code>from src.core.orchestrator import PipelineBuilder\n\nresult = await (\n    PipelineBuilder(orchestrator)\n    .create(\"analysis\")\n    .add(\"validator\")\n    .add(\"sql\")\n    .add(\"analyst\")\n    .run(user_context=user, initial_input=\"Show sales\")\n)\n</code></pre>"},{"location":"agents/workflows/#parallel-execution","title":"Parallel Execution","text":"<pre><code>from src.core.orchestrator import Workflow, AgentTask\n\nworkflow = Workflow(\n    name=\"parallel\",\n    tasks=[\n        AgentTask(id=\"q1\", agent_name=\"sql\", input_data=\"Get sales\"),\n        AgentTask(id=\"q2\", agent_name=\"sql\", input_data=\"Get orders\"),\n        AgentTask(\n            id=\"analyze\",\n            agent_name=\"analyst\",\n            dependencies=[\"q1\", \"q2\"],\n        ),\n    ],\n)\n</code></pre>"},{"location":"agents/workflows/#error-handling","title":"Error Handling","text":"<pre><code>task = AgentTask(\n    agent_name=\"sql\",\n    input_data=\"Complex query\",\n    max_retries=3,\n    timeout_seconds=60.0,\n)\n</code></pre>"},{"location":"api/database-adapters/","title":"Database Adapters","text":"<p>Connect to different database types.</p>"},{"location":"api/database-adapters/#connectionconfig","title":"ConnectionConfig","text":"<p>Base configuration for all database connections.</p> <pre><code>from src.database.multi_db import ConnectionConfig, DatabaseType\n\nconfig = ConnectionConfig(\n    name: str,                         # Connection identifier\n    db_type: DatabaseType,             # Database type enum\n    host: Optional[str] = None,        # Server hostname\n    port: Optional[int] = None,        # Server port\n    database: str,                     # Database name\n    username: Optional[str] = None,    # Username\n    password: Optional[str] = None,    # Password\n    connection_string: Optional[str] = None,  # Alternative to host/port\n)\n</code></pre>"},{"location":"api/database-adapters/#parameters","title":"Parameters","text":"Parameter Type Required Description <code>name</code> <code>str</code> Yes Unique identifier for the connection <code>db_type</code> <code>DatabaseType</code> Yes Database type enum <code>host</code> <code>str</code> No Server hostname <code>port</code> <code>int</code> No Server port <code>database</code> <code>str</code> Yes Database name or file path <code>username</code> <code>str</code> No Database username <code>password</code> <code>str</code> No Database password <code>connection_string</code> <code>str</code> No Full connection string (alternative)"},{"location":"api/database-adapters/#databasetype","title":"DatabaseType","text":"<pre><code>from src.database.multi_db import DatabaseType\n\nDatabaseType.MSSQL       # MS SQL Server\nDatabaseType.POSTGRESQL  # PostgreSQL\nDatabaseType.MYSQL       # MySQL\nDatabaseType.SQLITE      # SQLite\nDatabaseType.SNOWFLAKE   # Snowflake (coming soon)\nDatabaseType.BIGQUERY    # Google BigQuery (coming soon)\n</code></pre>"},{"location":"api/database-adapters/#mssqladapter","title":"MSSQLAdapter","text":""},{"location":"api/database-adapters/#class-definition","title":"Class Definition","text":"<pre><code>from src.database.multi_db import MSSQLAdapter\n\nadapter = MSSQLAdapter(config: ConnectionConfig)\n</code></pre>"},{"location":"api/database-adapters/#methods","title":"Methods","text":""},{"location":"api/database-adapters/#connect","title":"connect()","text":"<pre><code>async def connect() -&gt; None\n</code></pre> <p>Establish connection to MS SQL Server.</p>"},{"location":"api/database-adapters/#execute","title":"execute()","text":"<pre><code>async def execute(query: str, params: tuple = None) -&gt; List[Dict]\n</code></pre> <p>Execute SQL query and return results.</p>"},{"location":"api/database-adapters/#example","title":"Example","text":"<pre><code>from src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MSSQLAdapter(ConnectionConfig(\n    name=\"production\",\n    db_type=DatabaseType.MSSQL,\n    host=\"server.database.windows.net,1433\",\n    database=\"MyDatabase\",\n    username=\"admin\",\n    password=\"password\",\n))\n\nawait db.connect()\n\n# Execute query\nresults = await db.execute(\"SELECT TOP 10 * FROM users\")\nfor row in results:\n    print(row)\n</code></pre>"},{"location":"api/database-adapters/#azure-sql-database","title":"Azure SQL Database","text":"<pre><code>db = MSSQLAdapter(ConnectionConfig(\n    name=\"azure\",\n    db_type=DatabaseType.MSSQL,\n    host=\"myserver.database.windows.net,1433\",\n    database=\"MyDB\",\n    username=\"admin@myserver\",\n    password=\"password\",\n))\n</code></pre>"},{"location":"api/database-adapters/#windows-authentication","title":"Windows Authentication","text":"<pre><code>db = MSSQLAdapter(ConnectionConfig(\n    name=\"local\",\n    db_type=DatabaseType.MSSQL,\n    host=\"localhost\",\n    database=\"MyDB\",\n    # Omit username/password for Windows Auth\n))\n</code></pre>"},{"location":"api/database-adapters/#postgresqladapter","title":"PostgreSQLAdapter","text":""},{"location":"api/database-adapters/#example_1","title":"Example","text":"<pre><code>from src.database.multi_db import PostgreSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = PostgreSQLAdapter(ConnectionConfig(\n    name=\"postgres\",\n    db_type=DatabaseType.POSTGRESQL,\n    host=\"localhost\",\n    port=5432,\n    database=\"mydb\",\n    username=\"postgres\",\n    password=\"password\",\n))\n\nawait db.connect()\nresults = await db.execute(\"SELECT * FROM users LIMIT 10\")\n</code></pre>"},{"location":"api/database-adapters/#connection-string","title":"Connection String","text":"<pre><code>db = PostgreSQLAdapter(ConnectionConfig(\n    name=\"postgres\",\n    db_type=DatabaseType.POSTGRESQL,\n    connection_string=\"postgresql://user:pass@localhost:5432/mydb\",\n))\n</code></pre>"},{"location":"api/database-adapters/#mysqladapter","title":"MySQLAdapter","text":""},{"location":"api/database-adapters/#example_2","title":"Example","text":"<pre><code>from src.database.multi_db import MySQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MySQLAdapter(ConnectionConfig(\n    name=\"mysql\",\n    db_type=DatabaseType.MYSQL,\n    host=\"localhost\",\n    port=3306,\n    database=\"mydb\",\n    username=\"root\",\n    password=\"password\",\n))\n\nawait db.connect()\nresults = await db.execute(\"SELECT * FROM users LIMIT 10\")\n</code></pre>"},{"location":"api/database-adapters/#sqliteadapter","title":"SQLiteAdapter","text":""},{"location":"api/database-adapters/#file-database","title":"File Database","text":"<pre><code>from src.database.multi_db import SQLiteAdapter, ConnectionConfig, DatabaseType\n\ndb = SQLiteAdapter(ConnectionConfig(\n    name=\"sqlite\",\n    db_type=DatabaseType.SQLITE,\n    database=\"/path/to/database.db\",\n))\n\nawait db.connect()\n</code></pre>"},{"location":"api/database-adapters/#in-memory-database","title":"In-Memory Database","text":"<pre><code>db = SQLiteAdapter(ConnectionConfig(\n    name=\"memory\",\n    db_type=DatabaseType.SQLITE,\n    database=\":memory:\",\n))\n\nawait db.connect()\n\n# Create tables\nawait db.execute(\"\"\"\n    CREATE TABLE users (\n        id INTEGER PRIMARY KEY,\n        name TEXT,\n        email TEXT\n    )\n\"\"\")\n</code></pre>"},{"location":"api/database-adapters/#adapter-interface","title":"Adapter Interface","text":"<p>All adapters implement this interface:</p> <pre><code>class DatabaseAdapter(ABC):\n    @abstractmethod\n    async def connect(self) -&gt; None:\n        \"\"\"Establish database connection.\"\"\"\n        pass\n\n    @abstractmethod\n    async def execute(\n        self,\n        query: str,\n        params: tuple = None,\n    ) -&gt; List[Dict]:\n        \"\"\"Execute query and return results.\"\"\"\n        pass\n\n    @abstractmethod\n    async def disconnect(self) -&gt; None:\n        \"\"\"Close database connection.\"\"\"\n        pass\n</code></pre>"},{"location":"api/database-adapters/#using-with-metaagent","title":"Using with MetaAgent","text":"<pre><code># Create adapter\ndb = MSSQLAdapter(config)\nawait db.connect()\n\n# Create agent\nagent = MetaAgent(llm_client=llm)\n\n# Connect agent to database\nstats = await agent.connect(db_executor=db.execute)\n\nprint(f\"Dialect: {stats['dialect']}\")  # Auto-detected!\nprint(f\"Tables: {stats['tables']}\")\n</code></pre>"},{"location":"api/database-adapters/#auto-detection","title":"Auto-Detection","text":"<p>The agent automatically detects:</p> Feature MS SQL PostgreSQL MySQL SQLite Row limit <code>TOP</code> <code>LIMIT</code> <code>LIMIT</code> <code>LIMIT</code> Current date <code>GETDATE()</code> <code>NOW()</code> <code>NOW()</code> <code>datetime('now')</code> Identifiers <code>[brackets]</code> <code>\"quotes\"</code> <code>`backticks`</code> <code>\"quotes\"</code> Boolean <code>1/0</code> <code>true/false</code> <code>1/0</code> <code>1/0</code>"},{"location":"api/llm-clients/","title":"LLM Clients","text":"<p>Supported LLM providers and their configuration.</p>"},{"location":"api/llm-clients/#overview","title":"Overview","text":"<p>Agentic SQL supports multiple LLM providers:</p> Provider Class Status Azure OpenAI <code>AzureOpenAIClient</code> :material-check-circle: Ready OpenAI <code>OpenAIClient</code> :material-check-circle: Ready Anthropic <code>AnthropicClient</code> :material-check-circle: Ready Google <code>GoogleClient</code> :material-clock: Coming Ollama <code>OllamaClient</code> :material-clock: Coming"},{"location":"api/llm-clients/#azureopenaiclient","title":"AzureOpenAIClient","text":""},{"location":"api/llm-clients/#configuration","title":"Configuration","text":"<pre><code>from src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\n\nconfig = AzureOpenAIConfig(\n    api_key: str,                    # Required\n    azure_endpoint: str,             # Required\n    azure_deployment: str,           # Required\n    api_version: str = \"2024-02-01\", # Optional\n    temperature: float = 0.3,        # Optional\n    max_tokens: int = 2000,          # Optional\n)\n\nllm = AzureOpenAIClient(config)\n</code></pre>"},{"location":"api/llm-clients/#parameters","title":"Parameters","text":"Parameter Type Required Default Description <code>api_key</code> <code>str</code> Yes - Azure OpenAI API key <code>azure_endpoint</code> <code>str</code> Yes - Azure endpoint URL <code>azure_deployment</code> <code>str</code> Yes - Deployment name (e.g., \"gpt-4o\") <code>api_version</code> <code>str</code> No <code>\"2024-02-01\"</code> API version <code>temperature</code> <code>float</code> No <code>0.3</code> Response randomness (0-1) <code>max_tokens</code> <code>int</code> No <code>2000</code> Max response tokens"},{"location":"api/llm-clients/#example","title":"Example","text":"<pre><code>from src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\nimport os\n\nllm = AzureOpenAIClient(AzureOpenAIConfig(\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    azure_deployment=\"gpt-4o\",\n))\n\n# Use with MetaAgent\nagent = MetaAgent(llm_client=llm)\n</code></pre>"},{"location":"api/llm-clients/#openaiclient","title":"OpenAIClient","text":""},{"location":"api/llm-clients/#configuration_1","title":"Configuration","text":"<pre><code>from src.llm.openai_client import OpenAIClient, OpenAIConfig\n\nconfig = OpenAIConfig(\n    api_key: str,              # Required\n    model: str = \"gpt-4\",      # Optional\n    temperature: float = 0.3,  # Optional\n    max_tokens: int = 2000,    # Optional\n    organization: str = None,  # Optional\n)\n\nllm = OpenAIClient(config)\n</code></pre>"},{"location":"api/llm-clients/#parameters_1","title":"Parameters","text":"Parameter Type Required Default Description <code>api_key</code> <code>str</code> Yes - OpenAI API key <code>model</code> <code>str</code> No <code>\"gpt-4\"</code> Model name <code>temperature</code> <code>float</code> No <code>0.3</code> Response randomness <code>max_tokens</code> <code>int</code> No <code>2000</code> Max response tokens <code>organization</code> <code>str</code> No <code>None</code> Organization ID"},{"location":"api/llm-clients/#available-models","title":"Available Models","text":"Model Best For <code>gpt-4</code> Complex queries <code>gpt-4-turbo</code> Faster, large context <code>gpt-4o</code> Optimized performance <code>gpt-3.5-turbo</code> Simple queries, lower cost"},{"location":"api/llm-clients/#example_1","title":"Example","text":"<pre><code>from src.llm.openai_client import OpenAIClient, OpenAIConfig\n\nllm = OpenAIClient(OpenAIConfig(\n    api_key=\"sk-...\",\n    model=\"gpt-4\",\n    temperature=0.3,\n))\n\nagent = MetaAgent(llm_client=llm)\n</code></pre>"},{"location":"api/llm-clients/#anthropicclient","title":"AnthropicClient","text":""},{"location":"api/llm-clients/#configuration_2","title":"Configuration","text":"<pre><code>from src.llm.anthropic_client import AnthropicClient, AnthropicConfig\n\nconfig = AnthropicConfig(\n    api_key: str,                           # Required\n    model: str = \"claude-3-opus-20240229\",  # Optional\n    temperature: float = 0.3,               # Optional\n    max_tokens: int = 2000,                 # Optional\n)\n\nllm = AnthropicClient(config)\n</code></pre>"},{"location":"api/llm-clients/#parameters_2","title":"Parameters","text":"Parameter Type Required Default Description <code>api_key</code> <code>str</code> Yes - Anthropic API key <code>model</code> <code>str</code> No <code>\"claude-3-opus-20240229\"</code> Model name <code>temperature</code> <code>float</code> No <code>0.3</code> Response randomness <code>max_tokens</code> <code>int</code> No <code>2000</code> Max response tokens"},{"location":"api/llm-clients/#available-models_1","title":"Available Models","text":"Model Best For <code>claude-3-opus-20240229</code> Best quality <code>claude-3-sonnet-20240229</code> Balanced <code>claude-3-haiku-20240307</code> Fast, low cost"},{"location":"api/llm-clients/#example_2","title":"Example","text":"<pre><code>from src.llm.anthropic_client import AnthropicClient, AnthropicConfig\n\nllm = AnthropicClient(AnthropicConfig(\n    api_key=\"sk-ant-...\",\n    model=\"claude-3-opus-20240229\",\n))\n\nagent = MetaAgent(llm_client=llm)\n</code></pre>"},{"location":"api/llm-clients/#llm-interface","title":"LLM Interface","text":"<p>All LLM clients implement this interface:</p> <pre><code>class LLMClient(ABC):\n    @abstractmethod\n    async def generate(\n        self,\n        prompt: str,\n        max_tokens: int = 2000,\n        temperature: float = None,\n    ) -&gt; str:\n        \"\"\"Generate text from prompt.\"\"\"\n        pass\n</code></pre>"},{"location":"api/llm-clients/#custom-llm-client","title":"Custom LLM Client","text":"<p>Create your own LLM client:</p> <pre><code>from src.llm.base import LLMClient\n\nclass MyCustomLLM(LLMClient):\n    def __init__(self, config):\n        self.config = config\n\n    async def generate(\n        self,\n        prompt: str,\n        max_tokens: int = 2000,\n        temperature: float = None,\n    ) -&gt; str:\n        # Your implementation\n        response = await my_llm_api.call(prompt)\n        return response.text\n\n# Use with MetaAgent\nllm = MyCustomLLM(config)\nagent = MetaAgent(llm_client=llm)\n</code></pre>"},{"location":"api/llm-clients/#best-practices","title":"Best Practices","text":""},{"location":"api/llm-clients/#temperature","title":"Temperature","text":"Use Case Temperature SQL generation 0.1 - 0.3 Analysis 0.3 - 0.5 Creative 0.7 - 1.0 <p>Recommendation</p> <p>Use <code>temperature=0.3</code> for SQL generation. Lower values produce more consistent, deterministic output.</p>"},{"location":"api/llm-clients/#token-limits","title":"Token Limits","text":"Task Recommended <code>max_tokens</code> Simple query 500 Complex query 1000 Auto-learning 2000"},{"location":"api/llm-clients/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    result = await agent.query(\"...\")\nexcept Exception as e:\n    if \"rate_limit\" in str(e).lower():\n        # Wait and retry\n        await asyncio.sleep(60)\n        result = await agent.query(\"...\")\n    else:\n        raise\n</code></pre>"},{"location":"api/memory-manager/","title":"Memory Manager","text":"<p>Hybrid memory system for persistent knowledge.</p>"},{"location":"api/memory-manager/#memorymanager","title":"MemoryManager","text":""},{"location":"api/memory-manager/#constructor","title":"Constructor","text":"<pre><code>from src.memory.manager import MemoryManager, MemoryConfig\n\nmanager = MemoryManager(\n    config: MemoryConfig,\n    graph_store: Optional[MemoryStore] = None,\n    vector_store: Optional[MemoryStore] = None,\n    sql_store: Optional[MemoryStore] = None,\n    embedding_fn: Optional[Callable] = None,\n)\n</code></pre>"},{"location":"api/memory-manager/#memoryconfig","title":"MemoryConfig","text":"<pre><code>from src.memory.manager import MemoryConfig\n\nconfig = MemoryConfig(\n    enable_graph: bool = True,           # Graph relationships\n    enable_vector: bool = True,          # Semantic embeddings\n    enable_sql: bool = True,             # Structured persistence\n    vector_dimensions: int = 1536,       # Embedding size\n    similarity_threshold: float = 0.7,   # Search threshold\n    max_memories_per_query: int = 10,    # Results limit\n    memory_ttl_days: int = 90,           # Expiration\n    enable_compression: bool = True,     # Compress long content\n    enable_deduplication: bool = True,   # Prevent duplicates\n    consolidation_interval_hours: int = 24,\n)\n</code></pre>"},{"location":"api/memory-manager/#memorytype","title":"MemoryType","text":"<pre><code>from src.memory.manager import MemoryType\n\nMemoryType.CONVERSATION     # Chat history\nMemoryType.ENTITY_FACT      # Facts about entities\nMemoryType.SCHEMA           # Database schema\nMemoryType.QUERY_PATTERN    # Successful SQL patterns\nMemoryType.ERROR_PATTERN    # Error patterns to avoid\nMemoryType.USER_PREFERENCE  # User preferences\nMemoryType.SEMANTIC         # General knowledge\n</code></pre>"},{"location":"api/memory-manager/#memorypriority","title":"MemoryPriority","text":"<pre><code>from src.memory.manager import MemoryPriority\n\nMemoryPriority.CRITICAL  # Always retrieve (1.0)\nMemoryPriority.HIGH      # Important (0.8)\nMemoryPriority.MEDIUM    # Normal (0.6)\nMemoryPriority.LOW       # Background (0.4)\n</code></pre>"},{"location":"api/memory-manager/#methods","title":"Methods","text":""},{"location":"api/memory-manager/#add","title":"add()","text":"<pre><code>async def add(\n    content: str,\n    memory_type: MemoryType,\n    entity_id: Optional[str] = None,\n    process_id: Optional[str] = None,\n    session_id: Optional[str] = None,\n    metadata: Optional[Dict] = None,\n    priority: MemoryPriority = MemoryPriority.MEDIUM,\n) -&gt; Memory\n</code></pre> <p>Add raw content to memory (Extract phase).</p>"},{"location":"api/memory-manager/#example","title":"Example","text":"<pre><code>memory = await manager.add(\n    content=\"SELECT COUNT(*) FROM users WHERE active = true\",\n    memory_type=MemoryType.QUERY_PATTERN,\n    metadata={\"question\": \"How many active users?\", \"success\": True},\n    priority=MemoryPriority.HIGH,\n)\n</code></pre>"},{"location":"api/memory-manager/#cognify","title":"cognify()","text":"<pre><code>async def cognify(memory: Memory) -&gt; Memory\n</code></pre> <p>Transform content into structured knowledge (Cognify phase).</p> <ul> <li>Generates embeddings</li> <li>Extracts entities</li> <li>Finds relationships</li> </ul> <pre><code>memory = await manager.cognify(memory)\n</code></pre>"},{"location":"api/memory-manager/#memify","title":"memify()","text":"<pre><code>async def memify(memory: Memory) -&gt; Memory\n</code></pre> <p>Enrich memory with computed properties.</p> <ul> <li>Calculates relevance scores</li> <li>Compresses if needed</li> </ul> <pre><code>memory = await manager.memify(memory)\n</code></pre>"},{"location":"api/memory-manager/#store","title":"store()","text":"<pre><code>async def store(memory: Memory) -&gt; bool\n</code></pre> <p>Persist memory to storage backends (Load phase).</p> <pre><code>success = await manager.store(memory)\n</code></pre>"},{"location":"api/memory-manager/#ingest","title":"ingest()","text":"<pre><code>async def ingest(\n    content: str,\n    memory_type: MemoryType,\n    **kwargs,\n) -&gt; Memory\n</code></pre> <p>Complete ECL pipeline: Add \u2192 Cognify \u2192 Memify \u2192 Store.</p> <pre><code>memory = await manager.ingest(\n    content=\"Users table: id, name, email, created_at\",\n    memory_type=MemoryType.SCHEMA,\n    metadata={\"table\": \"users\"},\n)\n</code></pre>"},{"location":"api/memory-manager/#search","title":"search()","text":"<pre><code>async def search(\n    query: str,\n    memory_type: Optional[MemoryType] = None,\n    entity_id: Optional[str] = None,\n    session_id: Optional[str] = None,\n    limit: int = 10,\n    include_graph_context: bool = True,\n) -&gt; List[Memory]\n</code></pre> <p>Hybrid retrieval using vector similarity + graph traversal.</p>"},{"location":"api/memory-manager/#example_1","title":"Example","text":"<pre><code># Semantic search\nresults = await manager.search(\n    query=\"count users\",\n    memory_types=[MemoryType.QUERY_PATTERN],\n    limit=5,\n)\n\nfor r in results:\n    print(f\"Content: {r.content}\")\n    print(f\"Score: {r.relevance_score}\")\n</code></pre>"},{"location":"api/memory-manager/#consolidate","title":"consolidate()","text":"<pre><code>async def consolidate() -&gt; int\n</code></pre> <p>Consolidate memories: merge duplicates, prune old entries.</p> <pre><code>count = await manager.consolidate()\nprint(f\"Consolidated {count} memories\")\n</code></pre>"},{"location":"api/memory-manager/#memory-object","title":"Memory Object","text":"<pre><code>@dataclass\nclass Memory:\n    id: UUID\n    type: MemoryType\n    content: str\n    embedding: Optional[List[float]]\n    metadata: Dict[str, Any]\n    priority: MemoryPriority\n    entity_id: Optional[str]\n    process_id: Optional[str]\n    session_id: Optional[str]\n    created_at: datetime\n    updated_at: datetime\n    access_count: int\n    relevance_score: float\n</code></pre>"},{"location":"api/memory-manager/#ecl-pipeline","title":"ECL Pipeline","text":"<pre><code>graph LR\n    A[ADD] --&gt; B[COGNIFY]\n    B --&gt; C[MEMIFY]\n    C --&gt; D[STORE]\n\n    subgraph Extract\n    A\n    end\n\n    subgraph Transform\n    B\n    C\n    end\n\n    subgraph Load\n    D\n    end</code></pre> Phase Action ADD Parse content, extract metadata, deduplication check COGNIFY Generate embeddings, extract entities, find relationships MEMIFY Calculate relevance scores, compress if needed STORE Persist to Graph, Vector, and SQL stores"},{"location":"api/memory-manager/#complete-example","title":"Complete Example","text":"<pre><code>from src.memory.manager import (\n    MemoryManager,\n    MemoryConfig,\n    MemoryType,\n    MemoryPriority,\n)\n\n# Initialize\nmemory = MemoryManager(MemoryConfig())\n\n# Store successful query pattern\nawait memory.ingest(\n    content=\"SELECT COUNT(*) FROM users WHERE active = true\",\n    memory_type=MemoryType.QUERY_PATTERN,\n    metadata={\"question\": \"active users\", \"success\": True},\n    priority=MemoryPriority.HIGH,\n)\n\n# Store schema knowledge\nawait memory.ingest(\n    content=\"users table: id, name, email, active, created_at\",\n    memory_type=MemoryType.SCHEMA,\n    metadata={\"table\": \"users\"},\n)\n\n# Store error pattern\nawait memory.ingest(\n    content=\"LIMIT doesn't work in MSSQL, use TOP instead\",\n    memory_type=MemoryType.ERROR_PATTERN,\n    metadata={\"dialect\": \"mssql\"},\n)\n\n# Search\nresults = await memory.search(\n    query=\"count active users\",\n    memory_types=[MemoryType.QUERY_PATTERN],\n    limit=5,\n)\n\nfor r in results:\n    print(f\"Found: {r.content}\")\n    print(f\"Score: {r.relevance_score:.2f}\")\n</code></pre>"},{"location":"api/meta-agent/","title":"MetaAgent","text":"<p>The core intelligent agent for text-to-SQL conversion.</p>"},{"location":"api/meta-agent/#class-definition","title":"Class Definition","text":"<pre><code>class MetaAgent:\n    \"\"\"\n    META-LEARNING AGENT - PURE INTELLIGENCE\n\n    This agent:\n    1. THINKS - Analyzes each problem uniquely\n    2. RESEARCHES - Finds what worked for similar problems\n    3. DESIGNS - Creates custom approach (dynamic prompts!)\n    4. EXECUTES - Runs with intelligent error recovery\n    5. LEARNS - Updates knowledge from EVERY interaction\n    \"\"\"\n</code></pre>"},{"location":"api/meta-agent/#constructor","title":"Constructor","text":"<pre><code>MetaAgent(\n    llm_client: LLMClient,\n    storage_path: Optional[Path] = None,\n)\n</code></pre>"},{"location":"api/meta-agent/#parameters","title":"Parameters","text":"Parameter Type Required Default Description <code>llm_client</code> <code>LLMClient</code> Yes - LLM client instance (Azure, OpenAI, Anthropic) <code>storage_path</code> <code>Path</code> No <code>~/.vanna/meta_agent.json</code> Path for knowledge persistence"},{"location":"api/meta-agent/#example","title":"Example","text":"<pre><code>from src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\nfrom pathlib import Path\n\n# With default storage\nagent = MetaAgent(llm_client=llm)\n\n# With custom storage path\nagent = MetaAgent(\n    llm_client=llm,\n    storage_path=Path(\"./my_knowledge.json\"),\n)\n</code></pre>"},{"location":"api/meta-agent/#methods","title":"Methods","text":""},{"location":"api/meta-agent/#connect","title":"connect()","text":"<pre><code>async def connect(\n    db_executor: Callable,\n    driver: Optional[str] = None,\n) -&gt; Dict\n</code></pre> <p>Connect to a database and auto-discover schema and dialect.</p>"},{"location":"api/meta-agent/#parameters_1","title":"Parameters","text":"Parameter Type Required Default Description <code>db_executor</code> <code>Callable</code> Yes - Async function to execute SQL queries <code>driver</code> <code>str</code> No <code>None</code> Hint for database driver"},{"location":"api/meta-agent/#returns","title":"Returns","text":"<pre><code>{\n    \"dialect\": str,           # \"mssql\", \"postgresql\", \"mysql\", \"sqlite\"\n    \"tables\": int,            # Number of tables discovered\n    \"schema_insights\": int,   # Number of LLM-generated insights\n}\n</code></pre>"},{"location":"api/meta-agent/#example_1","title":"Example","text":"<pre><code>stats = await agent.connect(db_executor=db.execute)\n\nprint(f\"Dialect: {stats['dialect']}\")\nprint(f\"Tables: {stats['tables']}\")\nprint(f\"Insights: {stats['schema_insights']}\")\n</code></pre>"},{"location":"api/meta-agent/#what-happens","title":"What Happens","text":"<ol> <li>Probe Database - Runs test queries to detect dialect</li> <li>Discover Schema - Queries <code>INFORMATION_SCHEMA</code> for tables/columns</li> <li>Analyze Schema - LLM generates insights about relationships</li> <li>Store Learnings - Persists dialect and schema knowledge</li> </ol>"},{"location":"api/meta-agent/#query","title":"query()","text":"<pre><code>async def query(\n    question: str,\n) -&gt; Dict\n</code></pre> <p>Process a natural language question and return SQL results.</p>"},{"location":"api/meta-agent/#parameters_2","title":"Parameters","text":"Parameter Type Required Description <code>question</code> <code>str</code> Yes Natural language question"},{"location":"api/meta-agent/#returns_1","title":"Returns","text":"<pre><code>{\n    \"success\": bool,            # Whether query succeeded\n    \"sql\": str,                 # Generated SQL query\n    \"data\": List[Dict],         # Query results\n    \"row_count\": int,           # Number of rows returned\n    \"iterations\": int,          # Self-correction attempts (1-4)\n    \"problem_type\": str,        # LLM-classified problem type\n    \"execution_time_ms\": float, # Total execution time\n    \"error\": Optional[str],     # Error message if failed\n    \"steps_taken\": int,         # Processing steps\n}\n</code></pre>"},{"location":"api/meta-agent/#example_2","title":"Example","text":"<pre><code>result = await agent.query(\"How many orders last month?\")\n\nif result[\"success\"]:\n    print(f\"SQL: {result['sql']}\")\n    print(f\"Data: {result['data']}\")\n    print(f\"Iterations: {result['iterations']}\")\nelse:\n    print(f\"Error: {result['error']}\")\n</code></pre>"},{"location":"api/meta-agent/#processing-flow","title":"Processing Flow","text":"<pre><code>graph LR\n    A[THINK] --&gt; B[RESEARCH]\n    B --&gt; C[DESIGN]\n    C --&gt; D[EXECUTE]\n    D --&gt; E{Success?}\n    E --&gt;|Yes| F[LEARN]\n    E --&gt;|No| G{Retry?}\n    G --&gt;|Yes| D\n    G --&gt;|No| F</code></pre>"},{"location":"api/meta-agent/#auto_learn","title":"auto_learn()","text":"<pre><code>async def auto_learn(\n    intensity: str = \"medium\",\n) -&gt; Dict\n</code></pre> <p>Self-train on the connected database.</p>"},{"location":"api/meta-agent/#parameters_3","title":"Parameters","text":"Parameter Type Required Default Description <code>intensity</code> <code>str</code> No <code>\"medium\"</code> Training intensity level"},{"location":"api/meta-agent/#intensity-levels","title":"Intensity Levels","text":"Level Multiplier Use Case <code>light</code> 0.3\u00d7 Quick validation <code>medium</code> 0.6\u00d7 Balanced coverage <code>heavy</code> 1.0\u00d7 Comprehensive <code>exhaustive</code> 1.5\u00d7 Deep training"},{"location":"api/meta-agent/#question-calculation","title":"Question Calculation","text":"<p>Questions are calculated dynamically based on schema:</p> <pre><code>(tables \u00d7 2) + (columns \u00f7 10) + (relationships \u00f7 3) \u00d7 multiplier\n</code></pre> Database Tables Columns Light Medium Heavy Tiny 2 4 3 3 5 Small 5 17 4 8 14 Medium 15 68 13 27 45 Large 40 334 39 78 100 <p>Bounds</p> <ul> <li>Minimum: 3 questions</li> <li>Maximum: 100 questions</li> </ul>"},{"location":"api/meta-agent/#returns_2","title":"Returns","text":"<pre><code>{\n    \"domain\": str,              # Detected domain (\"ecommerce\", \"healthcare\", etc.)\n    \"questions_generated\": int, # Questions created by LLM\n    \"questions_tested\": int,    # Questions actually tested\n    \"successes\": int,           # Successful queries\n    \"failures\": int,            # Failed queries\n    \"success_rate\": float,      # 0.0 to 1.0\n    \"learnings\": List[Dict],    # What was learned from failures\n    \"schema_stats\": {\n        \"tables\": int,\n        \"total_columns\": int,\n    },\n    \"target_questions\": int,    # Calculated question count\n    \"intensity\": str,           # Requested intensity\n}\n</code></pre>"},{"location":"api/meta-agent/#example_3","title":"Example","text":"<pre><code>results = await agent.auto_learn(intensity=\"medium\")\n\nprint(f\"Domain: {results['domain']}\")\nprint(f\"Questions: {results['questions_tested']}\")\nprint(f\"Success rate: {results['success_rate']*100:.0f}%\")\nprint(f\"Schema: {results['schema_stats']}\")\n</code></pre>"},{"location":"api/meta-agent/#get_stats","title":"get_stats()","text":"<pre><code>def get_stats() -&gt; Dict\n</code></pre> <p>Get current knowledge statistics.</p>"},{"location":"api/meta-agent/#returns_3","title":"Returns","text":"<pre><code>{\n    \"dialect\": str,               # Current SQL dialect\n    \"tables\": int,                # Tables in schema\n    \"problem_types_learned\": int, # Unique problem types\n    \"actions_learned\": int,       # Fix strategies stored\n    \"solutions_stored\": int,      # Successful solutions\n    \"failures_analyzed\": int,     # Analyzed failures\n    \"dialect_learnings\": int,     # Dialect-specific learnings\n    \"schema_insights\": int,       # Schema insights\n}\n</code></pre>"},{"location":"api/meta-agent/#example_4","title":"Example","text":"<pre><code>stats = agent.get_stats()\n\nprint(f\"Dialect: {stats['dialect']}\")\nprint(f\"Solutions: {stats['solutions_stored']}\")\nprint(f\"Insights: {stats['schema_insights']}\")\n</code></pre>"},{"location":"api/meta-agent/#knowledge-structure","title":"Knowledge Structure","text":"<p>The agent stores learned knowledge in <code>MetaKnowledge</code>:</p> <pre><code>@dataclass\nclass MetaKnowledge:\n    # Successful patterns\n    successful_solutions: List[LearnedSolution]\n\n    # Failure analysis\n    failed_attempts: List[LearnedFailure]\n\n    # Dialect-specific learnings\n    dialect_learnings: List[str]\n\n    # Schema insights\n    schema_insights: List[str]\n\n    # Fix strategies\n    fix_strategies: List[Dict]\n\n    # TRUE LEARNING - Applied corrections\n    name_corrections: Dict[str, str]      # {\"categorie\": \"categories\"}\n    table_relationships: Dict[str, str]   # {\"products\": \"product_items\"}\n    column_mappings: Dict[str, str]       # {\"revenue\": \"total_amount\"}\n</code></pre>"},{"location":"api/meta-agent/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nfrom src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\nfrom src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\n\nasync def main():\n    # Setup LLM\n    llm = AzureOpenAIClient(AzureOpenAIConfig(\n        api_key=\"your-key\",\n        azure_endpoint=\"https://your-endpoint.openai.azure.com\",\n        azure_deployment=\"gpt-4o\",\n    ))\n\n    # Create agent\n    agent = MetaAgent(llm_client=llm)\n\n    # Connect to database\n    db = MSSQLAdapter(ConnectionConfig(\n        name=\"mydb\",\n        db_type=DatabaseType.MSSQL,\n        host=\"localhost\",\n        database=\"MyDB\",\n        username=\"user\",\n        password=\"pass\",\n    ))\n    await db.connect()\n\n    # Connect agent\n    stats = await agent.connect(db_executor=db.execute)\n    print(f\"Connected: {stats}\")\n\n    # Auto-train\n    learn_results = await agent.auto_learn(intensity=\"light\")\n    print(f\"Trained: {learn_results['success_rate']*100:.0f}%\")\n\n    # Query\n    result = await agent.query(\"Show top 10 customers\")\n    print(f\"SQL: {result['sql']}\")\n    print(f\"Data: {result['data']}\")\n\n    # Check stats\n    final_stats = agent.get_stats()\n    print(f\"Solutions learned: {final_stats['solutions_stored']}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"api/server/","title":"API Server","text":"<p>Production-ready REST API with FastAPI.</p>"},{"location":"api/server/#quick-start","title":"Quick Start","text":"<pre><code>from src.api.server import create_app, APIConfig\n\napp = create_app(\n    config=APIConfig(host=\"0.0.0.0\", port=8000),\n    sql_agent=agent,\n)\n\n# Run: uvicorn main:app\n</code></pre>"},{"location":"api/server/#apiconfig","title":"APIConfig","text":"<pre><code>from src.api.server import APIConfig\n\nconfig = APIConfig(\n    host: str = \"0.0.0.0\",\n    port: int = 8000,\n    debug: bool = False,\n    cors_origins: List[str] = [\"*\"],\n    enable_docs: bool = True,\n    rate_limit_per_minute: int = 100,\n    max_concurrent_requests: int = 50,\n    request_timeout_seconds: float = 300.0,\n)\n</code></pre>"},{"location":"api/server/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>host</code> <code>str</code> <code>\"0.0.0.0\"</code> Server host <code>port</code> <code>int</code> <code>8000</code> Server port <code>debug</code> <code>bool</code> <code>False</code> Debug mode <code>cors_origins</code> <code>List[str]</code> <code>[\"*\"]</code> CORS allowed origins <code>enable_docs</code> <code>bool</code> <code>True</code> Enable Swagger UI <code>rate_limit_per_minute</code> <code>int</code> <code>100</code> Rate limit per user <code>max_concurrent_requests</code> <code>int</code> <code>50</code> Concurrent request limit <code>request_timeout_seconds</code> <code>float</code> <code>300.0</code> Request timeout"},{"location":"api/server/#endpoints","title":"Endpoints","text":""},{"location":"api/server/#post-query","title":"POST /query","text":"<p>Execute natural language query.</p> RequestResponse <pre><code>curl -X POST http://localhost:8000/query \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -d '{\n    \"question\": \"How many users signed up last month?\",\n    \"include_sql\": true,\n    \"include_explanation\": true,\n    \"max_rows\": 100\n  }'\n</code></pre> <pre><code>{\n  \"success\": true,\n  \"conversation_id\": \"conv_123\",\n  \"question\": \"How many users signed up last month?\",\n  \"sql\": \"SELECT COUNT(*) FROM users WHERE ...\",\n  \"data\": [{\"count\": 1234}],\n  \"columns\": [\"count\"],\n  \"row_count\": 1,\n  \"explanation\": \"This query counts users...\",\n  \"execution_time_ms\": 145.5\n}\n</code></pre>"},{"location":"api/server/#post-querystream","title":"POST /query/stream","text":"<p>Execute with Server-Sent Events streaming.</p> RequestResponse (SSE) <pre><code>curl -N \"http://localhost:8000/query/stream?q=Show+sales+trends\" \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n</code></pre> <pre><code>event: thinking\ndata: {\"step\": \"Analyzing question...\"}\n\nevent: sql\ndata: {\"sql\": \"SELECT month, SUM(amount) FROM sales GROUP BY month\"}\n\nevent: data\ndata: {\"rows\": [{\"month\": \"Jan\", \"total\": 10000}]}\n\nevent: explanation\ndata: {\"text\": \"Sales show an upward trend...\"}\n\nevent: done\ndata: {\"success\": true, \"execution_time_ms\": 234}\n</code></pre>"},{"location":"api/server/#get-health","title":"GET /health","text":"<p>Health check endpoint.</p> <pre><code>curl http://localhost:8000/health\n</code></pre> <pre><code>{\n  \"status\": \"healthy\",\n  \"version\": \"2.0.0\"\n}\n</code></pre>"},{"location":"api/server/#get-schema","title":"GET /schema","text":"<p>Get database schema.</p> <pre><code>curl http://localhost:8000/schema \\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n</code></pre> <pre><code>{\n  \"tables\": [\n    {\n      \"name\": \"users\",\n      \"columns\": [\"id\", \"name\", \"email\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"api/server/#authentication","title":"Authentication","text":""},{"location":"api/server/#jwtuserresolver","title":"JWTUserResolver","text":"<pre><code>from src.api.auth import JWTUserResolver\n\nresolver = JWTUserResolver(\n    secret_key: str,\n    algorithm: str = \"HS256\",\n)\n\napp = create_app(\n    config=config,\n    sql_agent=agent,\n    user_resolver=resolver.resolve,\n)\n</code></pre> <p>JWT payload:</p> <pre><code>{\n  \"sub\": \"user123\",\n  \"roles\": [\"analyst\", \"viewer\"],\n  \"exp\": 1234567890\n}\n</code></pre>"},{"location":"api/server/#apikeyresolver","title":"APIKeyResolver","text":"<pre><code>from src.api.auth import APIKeyResolver\n\nresolver = APIKeyResolver(\n    api_keys={\n        \"key_abc123\": \"user1\",\n        \"key_def456\": \"user2\",\n    },\n)\n</code></pre> <p>Usage: <code>Authorization: Bearer key_abc123</code></p>"},{"location":"api/server/#sse-client-javascript","title":"SSE Client (JavaScript)","text":"<pre><code>const eventSource = new EventSource(\n  '/query/stream?q=' + encodeURIComponent(question)\n);\n\neventSource.addEventListener('thinking', (e) =&gt; {\n  showSpinner(JSON.parse(e.data));\n});\n\neventSource.addEventListener('sql', (e) =&gt; {\n  displaySQL(JSON.parse(e.data).sql);\n});\n\neventSource.addEventListener('data', (e) =&gt; {\n  renderTable(JSON.parse(e.data).rows);\n});\n\neventSource.addEventListener('done', (e) =&gt; {\n  eventSource.close();\n});\n\neventSource.addEventListener('error', (e) =&gt; {\n  showError(e.data);\n  eventSource.close();\n});\n</code></pre>"},{"location":"api/server/#complete-example","title":"Complete Example","text":"<pre><code>import os\nimport asyncio\nfrom src.api.server import create_app, APIConfig\nfrom src.api.auth import JWTUserResolver\nfrom src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\nfrom src.database.multi_db import PostgreSQLAdapter, ConnectionConfig, DatabaseType\n\nasync def create_agent():\n    llm = AzureOpenAIClient(AzureOpenAIConfig(\n        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n        azure_deployment=\"gpt-4o\",\n    ))\n\n    db = PostgreSQLAdapter(ConnectionConfig(\n        name=\"production\",\n        db_type=DatabaseType.POSTGRESQL,\n        connection_string=os.getenv(\"DATABASE_URL\"),\n    ))\n    await db.connect()\n\n    agent = MetaAgent(llm_client=llm)\n    await agent.connect(db_executor=db.execute)\n    await agent.auto_learn(intensity=\"light\")\n\n    return agent\n\nagent = asyncio.run(create_agent())\n\nconfig = APIConfig(\n    host=\"0.0.0.0\",\n    port=int(os.getenv(\"PORT\", 8000)),\n    cors_origins=os.getenv(\"CORS_ORIGINS\", \"*\").split(\",\"),\n)\n\nresolver = JWTUserResolver(secret_key=os.getenv(\"JWT_SECRET\"))\n\napp = create_app(\n    config=config,\n    sql_agent=agent,\n    user_resolver=resolver.resolve,\n)\n\n# Run: uvicorn server:app --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"api/server/#docker-deployment","title":"Docker Deployment","text":"Dockerfiledocker-compose.yml <pre><code>FROM python:3.11-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <pre><code>version: '3.8'\n\nservices:\n  api:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}\n      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}\n      - DATABASE_URL=${DATABASE_URL}\n      - JWT_SECRET=${JWT_SECRET}\n    restart: unless-stopped\n</code></pre>"},{"location":"databases/","title":"Database Support","text":"<p>Agentic SQL works with any SQL database.</p>"},{"location":"databases/#supported-databases","title":"Supported Databases","text":"Database Adapter Status MS SQL Server <code>MSSQLAdapter</code> :material-check-circle:{ .status-ready } Ready PostgreSQL <code>PostgreSQLAdapter</code> :material-check-circle:{ .status-ready } Ready MySQL <code>MySQLAdapter</code> :material-check-circle:{ .status-ready } Ready SQLite <code>SQLiteAdapter</code> :material-check-circle:{ .status-ready } Ready Snowflake <code>SnowflakeAdapter</code> :material-clock:{ .status-coming } Coming BigQuery <code>BigQueryAdapter</code> :material-clock:{ .status-coming } Coming"},{"location":"databases/#auto-detection","title":"Auto-Detection","text":"<p>The agent automatically detects your database type and adapts:</p> <pre><code>stats = await agent.connect(db_executor=db.execute)\nprint(f\"Detected: {stats['dialect']}\")  # \"mssql\", \"postgresql\", etc.\n</code></pre>"},{"location":"databases/#dialect-differences","title":"Dialect Differences","text":"Feature MS SQL PostgreSQL MySQL SQLite Row limit <code>TOP n</code> <code>LIMIT n</code> <code>LIMIT n</code> <code>LIMIT n</code> Current date <code>GETDATE()</code> <code>NOW()</code> <code>NOW()</code> <code>datetime('now')</code> Identifiers <code>[brackets]</code> <code>\"quotes\"</code> <code>`backticks`</code> <code>\"quotes\"</code> Boolean <code>1/0</code> <code>true/false</code> <code>1/0</code> <code>1/0</code> String concat <code>+</code> <code>\\|\\|</code> <code>CONCAT()</code> <code>\\|\\|</code>"},{"location":"databases/#quick-start","title":"Quick Start","text":"MS SQL ServerPostgreSQLMySQLSQLite <pre><code>from src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MSSQLAdapter(ConnectionConfig(\n    name=\"mydb\",\n    db_type=DatabaseType.MSSQL,\n    host=\"server.database.windows.net,1433\",\n    database=\"MyDB\",\n    username=\"user\",\n    password=\"pass\",\n))\nawait db.connect()\n</code></pre> <pre><code>from src.database.multi_db import PostgreSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = PostgreSQLAdapter(ConnectionConfig(\n    name=\"mydb\",\n    db_type=DatabaseType.POSTGRESQL,\n    host=\"localhost\",\n    port=5432,\n    database=\"mydb\",\n    username=\"postgres\",\n    password=\"pass\",\n))\nawait db.connect()\n</code></pre> <pre><code>from src.database.multi_db import MySQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MySQLAdapter(ConnectionConfig(\n    name=\"mydb\",\n    db_type=DatabaseType.MYSQL,\n    host=\"localhost\",\n    port=3306,\n    database=\"mydb\",\n    username=\"root\",\n    password=\"pass\",\n))\nawait db.connect()\n</code></pre> <pre><code>from src.database.multi_db import SQLiteAdapter, ConnectionConfig, DatabaseType\n\ndb = SQLiteAdapter(ConnectionConfig(\n    name=\"mydb\",\n    db_type=DatabaseType.SQLITE,\n    database=\"/path/to/db.sqlite\",  # or \":memory:\"\n))\nawait db.connect()\n</code></pre>"},{"location":"databases/mssql/","title":"MS SQL Server","text":"<p>Connect to Microsoft SQL Server.</p>"},{"location":"databases/mssql/#installation","title":"Installation","text":"<pre><code>pip install pyodbc\n</code></pre> <p>Also install ODBC Driver 17 or 18 for SQL Server.</p>"},{"location":"databases/mssql/#connection","title":"Connection","text":"<pre><code>from src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MSSQLAdapter(ConnectionConfig(\n    name=\"mssql\",\n    db_type=DatabaseType.MSSQL,\n    host=\"server.database.windows.net,1433\",\n    database=\"MyDatabase\",\n    username=\"user\",\n    password=\"password\",\n))\n\nawait db.connect()\n</code></pre>"},{"location":"databases/mssql/#azure-sql-database","title":"Azure SQL Database","text":"<pre><code>db = MSSQLAdapter(ConnectionConfig(\n    name=\"azure\",\n    db_type=DatabaseType.MSSQL,\n    host=\"myserver.database.windows.net,1433\",\n    database=\"MyDB\",\n    username=\"admin@myserver\",\n    password=\"password\",\n))\n</code></pre>"},{"location":"databases/mssql/#auto-detected-features","title":"Auto-Detected Features","text":"Feature MS SQL Syntax Row limit <code>SELECT TOP 10 *</code> Current date <code>GETDATE()</code> Date diff <code>DATEDIFF(day, a, b)</code> Identifiers <code>[TableName]</code> String concat <code>'a' + 'b'</code>"},{"location":"databases/mysql/","title":"MySQL","text":"<p>Connect to MySQL / MariaDB.</p>"},{"location":"databases/mysql/#installation","title":"Installation","text":"<pre><code>pip install -e \".[mysql]\"\n</code></pre>"},{"location":"databases/mysql/#connection","title":"Connection","text":"<pre><code>from src.database.multi_db import MySQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MySQLAdapter(ConnectionConfig(\n    name=\"mysql\",\n    db_type=DatabaseType.MYSQL,\n    host=\"localhost\",\n    port=3306,\n    database=\"mydb\",\n    username=\"root\",\n    password=\"password\",\n))\n\nawait db.connect()\n</code></pre>"},{"location":"databases/mysql/#auto-detected-features","title":"Auto-Detected Features","text":"Feature MySQL Syntax Row limit <code>LIMIT 10</code> Current date <code>NOW()</code> Identifiers <code>`TableName`</code> Auto increment <code>AUTO_INCREMENT</code>"},{"location":"databases/postgresql/","title":"PostgreSQL","text":"<p>Connect to PostgreSQL.</p>"},{"location":"databases/postgresql/#installation","title":"Installation","text":"<pre><code>pip install -e \".[postgres]\"\n</code></pre>"},{"location":"databases/postgresql/#connection","title":"Connection","text":"<pre><code>from src.database.multi_db import PostgreSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = PostgreSQLAdapter(ConnectionConfig(\n    name=\"postgres\",\n    db_type=DatabaseType.POSTGRESQL,\n    host=\"localhost\",\n    port=5432,\n    database=\"mydb\",\n    username=\"postgres\",\n    password=\"password\",\n))\n\nawait db.connect()\n</code></pre>"},{"location":"databases/postgresql/#connection-string","title":"Connection String","text":"<pre><code>db = PostgreSQLAdapter(ConnectionConfig(\n    name=\"postgres\",\n    db_type=DatabaseType.POSTGRESQL,\n    connection_string=\"postgresql://user:pass@localhost:5432/mydb\",\n))\n</code></pre>"},{"location":"databases/postgresql/#auto-detected-features","title":"Auto-Detected Features","text":"Feature PostgreSQL Syntax Row limit <code>LIMIT 10</code> Current date <code>NOW()</code> Date diff <code>date1 - date2</code> Identifiers <code>\"TableName\"</code> Boolean <code>true/false</code>"},{"location":"databases/sqlite/","title":"SQLite","text":"<p>Connect to SQLite databases.</p>"},{"location":"databases/sqlite/#installation","title":"Installation","text":"<pre><code>pip install -e \".[sqlite]\"\n</code></pre>"},{"location":"databases/sqlite/#file-database","title":"File Database","text":"<pre><code>from src.database.multi_db import SQLiteAdapter, ConnectionConfig, DatabaseType\n\ndb = SQLiteAdapter(ConnectionConfig(\n    name=\"sqlite\",\n    db_type=DatabaseType.SQLITE,\n    database=\"/path/to/database.db\",\n))\n\nawait db.connect()\n</code></pre>"},{"location":"databases/sqlite/#in-memory-database","title":"In-Memory Database","text":"<pre><code>db = SQLiteAdapter(ConnectionConfig(\n    name=\"memory\",\n    db_type=DatabaseType.SQLITE,\n    database=\":memory:\",\n))\n\nawait db.connect()\n\n# Create tables\nawait db.execute(\"\"\"\n    CREATE TABLE users (\n        id INTEGER PRIMARY KEY,\n        name TEXT\n    )\n\"\"\")\n</code></pre>"},{"location":"databases/sqlite/#auto-detected-features","title":"Auto-Detected Features","text":"Feature SQLite Syntax Row limit <code>LIMIT 10</code> Current date <code>datetime('now')</code> Auto increment <code>INTEGER PRIMARY KEY</code>"},{"location":"examples/snippets/","title":"Code Snippets","text":"<p>Copy-paste ready code examples.</p>"},{"location":"examples/snippets/#basic-query","title":"Basic Query","text":"<pre><code>import asyncio\nfrom src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\n\nasync def main():\n    llm = AzureOpenAIClient(AzureOpenAIConfig(\n        api_key=\"your-key\",\n        azure_endpoint=\"https://your-endpoint.openai.azure.com\",\n        azure_deployment=\"gpt-4o\",\n    ))\n\n    agent = MetaAgent(llm_client=llm)\n    await agent.connect(db_executor=db.execute)\n\n    result = await agent.query(\"How many users?\")\n    print(result[\"data\"])\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/snippets/#with-auto-learning","title":"With Auto-Learning","text":"<pre><code>await agent.connect(db_executor=db.execute)\nawait agent.auto_learn(intensity=\"medium\")\nresult = await agent.query(\"Show top customers\")\n</code></pre>"},{"location":"examples/snippets/#api-server","title":"API Server","text":"<pre><code>from src.api.server import create_app, APIConfig\n\napp = create_app(\n    config=APIConfig(host=\"0.0.0.0\", port=8000),\n    sql_agent=agent,\n)\n</code></pre>"},{"location":"examples/snippets/#error-handling","title":"Error Handling","text":"<pre><code>result = await agent.query(\"...\")\n\nif result[\"success\"]:\n    print(result[\"data\"])\nelse:\n    print(f\"Error: {result['error']}\")\n</code></pre>"},{"location":"examples/tutorials/","title":"Tutorials","text":"<p>Step-by-step tutorials to master Agentic SQL.</p>"},{"location":"examples/tutorials/#available-tutorials","title":"Available Tutorials","text":"# Tutorial Description 01 Quickstart Your first query 02 Databases Connect to different databases 03 Auto-Learning Train the agent 04 Memory Persistent knowledge 05 Multi-Agent Workflows 06 API Server REST API 07 Complete Full demo"},{"location":"examples/tutorials/#running-tutorials","title":"Running Tutorials","text":"<pre><code>cd examples\npython 01_quickstart.py\n</code></pre>"},{"location":"examples/tutorials/#prerequisites","title":"Prerequisites","text":"<pre><code>export AZURE_OPENAI_API_KEY=your-key\nexport AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com\n</code></pre>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Environment setup and configuration options.</p>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file in your project root:</p> .env<pre><code># LLM Configuration (choose one provider)\n\n# Azure OpenAI\nAZURE_OPENAI_API_KEY=your-api-key\nAZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com\nAZURE_OPENAI_DEPLOYMENT=gpt-4o\nAZURE_OPENAI_API_VERSION=2024-02-01\n\n# OpenAI\nOPENAI_API_KEY=sk-...\n\n# Anthropic\nANTHROPIC_API_KEY=sk-ant-...\n\n# Database\nDB_HOST=localhost\nDB_PORT=1433\nDB_NAME=MyDatabase\nDB_USER=user\nDB_PASSWORD=password\n\n# Or connection string\nDATABASE_URL=postgresql://user:pass@localhost:5432/mydb\n\n# API Server\nAPI_HOST=0.0.0.0\nAPI_PORT=8000\nJWT_SECRET=your-secret-key\n\n# Memory Storage\nVECTOR_STORE_PATH=./data/vector\nGRAPH_STORE_PATH=./data/graph\n\n# Logging\nLOG_LEVEL=INFO\n</code></pre>"},{"location":"getting-started/configuration/#loading-environment-variables","title":"Loading Environment Variables","text":"<pre><code>from dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\n# Use in code\napi_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n</code></pre>"},{"location":"getting-started/configuration/#knowledge-persistence","title":"Knowledge Persistence","text":"<p>All learned knowledge is automatically saved to:</p> <pre><code>~/.vanna/meta_agent.json\n</code></pre>"},{"location":"getting-started/configuration/#knowledge-structure","title":"Knowledge Structure","text":"~/.vanna/meta_agent.json<pre><code>{\n  \"successful_solutions\": [\n    {\n      \"question\": \"How many users?\",\n      \"sql\": \"SELECT COUNT(*) FROM users\",\n      \"problem_type\": \"counting\",\n      \"was_corrected\": false\n    }\n  ],\n  \"failed_attempts\": [...],\n  \"dialect_learnings\": [\n    \"DIALECT: mssql - Uses TOP instead of LIMIT\"\n  ],\n  \"schema_insights\": [\n    \"- Users table has email, name columns\"\n  ],\n  \"name_corrections\": {\n    \"categories\": \"Category\"\n  },\n  \"table_relationships\": {\n    \"orders\": \"joins with customers\"\n  },\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre>"},{"location":"getting-started/configuration/#custom-storage-path","title":"Custom Storage Path","text":"<pre><code>from pathlib import Path\n\nagent = MetaAgent(\n    llm_client=llm,\n    storage_path=Path(\"./my_knowledge.json\"),\n)\n</code></pre>"},{"location":"getting-started/configuration/#llm-configuration","title":"LLM Configuration","text":""},{"location":"getting-started/configuration/#azure-openai","title":"Azure OpenAI","text":"<pre><code>from src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\n\nllm = AzureOpenAIClient(AzureOpenAIConfig(\n    api_key=\"your-key\",\n    azure_endpoint=\"https://your-endpoint.openai.azure.com\",\n    azure_deployment=\"gpt-4o\",\n    api_version=\"2024-02-01\",\n    temperature=0.3,  # Lower = more deterministic\n    max_tokens=2000,\n))\n</code></pre>"},{"location":"getting-started/configuration/#openai","title":"OpenAI","text":"<pre><code>from src.llm.openai_client import OpenAIClient, OpenAIConfig\n\nllm = OpenAIClient(OpenAIConfig(\n    api_key=\"sk-...\",\n    model=\"gpt-4\",\n    temperature=0.3,\n    max_tokens=2000,\n))\n</code></pre>"},{"location":"getting-started/configuration/#anthropic","title":"Anthropic","text":"<pre><code>from src.llm.anthropic_client import AnthropicClient, AnthropicConfig\n\nllm = AnthropicClient(AnthropicConfig(\n    api_key=\"sk-ant-...\",\n    model=\"claude-3-opus-20240229\",\n    temperature=0.3,\n    max_tokens=2000,\n))\n</code></pre>"},{"location":"getting-started/configuration/#database-configuration","title":"Database Configuration","text":""},{"location":"getting-started/configuration/#connection-config","title":"Connection Config","text":"<pre><code>from src.database.multi_db import ConnectionConfig, DatabaseType\n\nconfig = ConnectionConfig(\n    name=\"my_database\",        # Identifier\n    db_type=DatabaseType.MSSQL,\n    host=\"localhost\",\n    port=1433,\n    database=\"MyDB\",\n    username=\"user\",\n    password=\"password\",\n\n    # Or use connection string\n    connection_string=\"...\",\n\n    # Optional settings\n    pool_size=10,\n    pool_max_overflow=20,\n    connect_timeout=30,\n)\n</code></pre>"},{"location":"getting-started/configuration/#database-types","title":"Database Types","text":"<pre><code>from src.database.multi_db import DatabaseType\n\nDatabaseType.MSSQL       # MS SQL Server\nDatabaseType.POSTGRESQL  # PostgreSQL\nDatabaseType.MYSQL       # MySQL\nDatabaseType.SQLITE      # SQLite\nDatabaseType.SNOWFLAKE   # Snowflake\nDatabaseType.BIGQUERY    # Google BigQuery\n</code></pre>"},{"location":"getting-started/configuration/#memory-configuration","title":"Memory Configuration","text":"<pre><code>from src.memory.manager import MemoryManager, MemoryConfig\n\nmemory = MemoryManager(MemoryConfig(\n    enable_graph=True,         # Graph relationships\n    enable_vector=True,        # Semantic embeddings\n    enable_sql=True,           # Structured persistence\n\n    vector_dimensions=1536,    # OpenAI embedding size\n    similarity_threshold=0.7,\n    max_memories_per_query=10,\n    memory_ttl_days=90,\n\n    enable_compression=True,\n    enable_deduplication=True,\n))\n</code></pre>"},{"location":"getting-started/configuration/#api-server-configuration","title":"API Server Configuration","text":"<pre><code>from src.api.server import APIConfig\n\nconfig = APIConfig(\n    host=\"0.0.0.0\",\n    port=8000,\n    debug=False,\n\n    # CORS\n    cors_origins=[\"*\"],  # Or specific origins\n\n    # Rate limiting\n    rate_limit_per_minute=100,\n    max_concurrent_requests=50,\n\n    # Timeouts\n    request_timeout_seconds=300.0,\n\n    # Documentation\n    enable_docs=True,  # Swagger at /docs\n)\n</code></pre>"},{"location":"getting-started/configuration/#logging","title":"Logging","text":"<pre><code>import logging\n\n# Set log level\nlogging.basicConfig(level=logging.INFO)\n\n# Or for specific modules\nlogging.getLogger(\"src.intelligence\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"getting-started/configuration/#log-levels","title":"Log Levels","text":"Level Use Case <code>DEBUG</code> Detailed execution traces <code>INFO</code> Normal operation <code>WARNING</code> Potential issues <code>ERROR</code> Errors that need attention"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Get Agentic SQL up and running in minutes.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"Requirement Version Python 3.10, 3.11, or 3.12 pip or uv Latest"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":"uv (Recommended)pippip (from PyPI) <pre><code># Clone repository\ngit clone https://github.com/bharatmohanthakur/Agentic-sql.git\ncd Agentic-sql\n\n# Install with uv\nuv sync\n</code></pre> <pre><code># Clone repository\ngit clone https://github.com/bharatmohanthakur/Agentic-sql.git\ncd Agentic-sql\n\n# Install with pip\npip install -e .\n</code></pre> <pre><code># Coming soon\npip install agentic-sql\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":""},{"location":"getting-started/installation/#core-dependencies","title":"Core Dependencies","text":"<p>These are installed automatically:</p> Package Version Purpose <code>openai</code> \u22652.16.0 OpenAI/Azure OpenAI client <code>pydantic</code> \u22652.0.0 Data validation <code>pyodbc</code> \u22655.3.0 MS SQL Server connectivity <code>python-dotenv</code> \u22651.2.1 Environment variables <code>typing-extensions</code> \u22654.0.0 Type hints"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Install extras based on your needs:</p> LLM ProvidersDatabasesMemory &amp; StorageAPI &amp; VisualizationFull Installation <pre><code># OpenAI (included in core)\npip install -e \".[openai]\"\n\n# Anthropic Claude\npip install -e \".[anthropic]\"\n\n# All LLM providers\npip install -e \".[all-llms]\"\n</code></pre> Extra Packages <code>openai</code> openai\u22651.0.0 <code>anthropic</code> anthropic\u22650.18.0 <code>all-llms</code> openai, anthropic, google-generativeai <pre><code># PostgreSQL\npip install -e \".[postgres]\"\n\n# MySQL\npip install -e \".[mysql]\"\n\n# SQLite\npip install -e \".[sqlite]\"\n</code></pre> Extra Packages <code>postgres</code> asyncpg\u22650.28.0, psycopg2-binary\u22652.9.0 <code>mysql</code> aiomysql\u22650.2.0 <code>sqlite</code> aiosqlite\u22650.19.0 <code>snowflake</code> snowflake-connector-python\u22653.0.0 <code>bigquery</code> google-cloud-bigquery\u22653.0.0 <pre><code># Vector store (ChromaDB)\npip install -e \".[vector]\"\n\n# Graph store (Neo4j)\npip install -e \".[graph]\"\n\n# Full memory system\npip install -e \".[memory]\"\n</code></pre> Extra Packages <code>vector</code> chromadb\u22650.4.0, pgvector\u22650.2.0 <code>graph</code> neo4j\u22655.0.0 <pre><code># FastAPI server\npip install -e \".[api]\"\n\n# JWT authentication\npip install -e \".[auth]\"\n\n# Visualization\npip install -e \".[viz]\"\n</code></pre> Extra Packages <code>api</code> fastapi\u22650.100.0, uvicorn\u22650.22.0, sse-starlette\u22651.6.0 <code>auth</code> PyJWT\u22652.8.0 <code>viz</code> plotly\u22655.0.0, pandas\u22652.0.0 <pre><code># Everything\npip install -e \".[all]\"\n</code></pre>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#ms-sql-server","title":"MS SQL Server","text":"<p>If connecting to MS SQL Server, install ODBC Driver:</p> WindowsmacOSUbuntu/Debian <p>Download from Microsoft</p> <pre><code>brew install microsoft/mssql-release/msodbcsql18\n</code></pre> <pre><code>curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\ncurl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list\napt-get update\nACCEPT_EULA=Y apt-get install -y msodbcsql18\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Test import\nfrom src.intelligence.meta_agent import MetaAgent\nprint(\"\u2713 Agentic SQL installed successfully!\")\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Your first query in 5 minutes</li> <li>Configuration - Environment setup</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Your first query in 5 minutes.</p>"},{"location":"getting-started/quickstart/#step-1-setup-llm-client","title":"Step 1: Setup LLM Client","text":"Azure OpenAIOpenAIAnthropic Claude <pre><code>from src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\n\nllm = AzureOpenAIClient(AzureOpenAIConfig(\n    api_key=\"your-api-key\",\n    azure_endpoint=\"https://your-endpoint.openai.azure.com\",\n    azure_deployment=\"gpt-4o\",\n    api_version=\"2024-02-01\",\n))\n</code></pre> <pre><code>from src.llm.openai_client import OpenAIClient, OpenAIConfig\n\nllm = OpenAIClient(OpenAIConfig(\n    api_key=\"sk-...\",\n    model=\"gpt-4\",\n))\n</code></pre> <pre><code>from src.llm.anthropic_client import AnthropicClient, AnthropicConfig\n\nllm = AnthropicClient(AnthropicConfig(\n    api_key=\"sk-ant-...\",\n    model=\"claude-3-opus-20240229\",\n))\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-create-the-agent","title":"Step 2: Create the Agent","text":"<pre><code>from src.intelligence.meta_agent import MetaAgent\n\nagent = MetaAgent(llm_client=llm)\n</code></pre> <p>That's it! No configuration needed.</p>"},{"location":"getting-started/quickstart/#step-3-connect-to-database","title":"Step 3: Connect to Database","text":"MS SQL ServerPostgreSQLSQLite <pre><code>from src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = MSSQLAdapter(ConnectionConfig(\n    name=\"my_database\",\n    db_type=DatabaseType.MSSQL,\n    host=\"server.database.windows.net,1433\",\n    database=\"MyDatabase\",\n    username=\"user\",\n    password=\"password\",\n))\nawait db.connect()\n</code></pre> <pre><code>from src.database.multi_db import PostgreSQLAdapter, ConnectionConfig, DatabaseType\n\ndb = PostgreSQLAdapter(ConnectionConfig(\n    name=\"my_database\",\n    db_type=DatabaseType.POSTGRESQL,\n    host=\"localhost\",\n    port=5432,\n    database=\"mydb\",\n    username=\"postgres\",\n    password=\"password\",\n))\nawait db.connect()\n</code></pre> <pre><code>from src.database.multi_db import SQLiteAdapter, ConnectionConfig, DatabaseType\n\ndb = SQLiteAdapter(ConnectionConfig(\n    name=\"my_database\",\n    db_type=DatabaseType.SQLITE,\n    database=\"/path/to/database.db\",  # or \":memory:\"\n))\nawait db.connect()\n</code></pre>"},{"location":"getting-started/quickstart/#step-4-connect-agent","title":"Step 4: Connect Agent","text":"<pre><code>stats = await agent.connect(db_executor=db.execute)\n\nprint(f\"Dialect: {stats['dialect']}\")      # e.g., \"mssql\"\nprint(f\"Tables: {stats['tables']}\")        # e.g., 25\nprint(f\"Insights: {stats['schema_insights']}\")  # e.g., 19\n</code></pre> <p>What happens automatically</p> <ul> <li>Probes database to detect SQL dialect</li> <li>Discovers all tables and columns</li> <li>Identifies relationships</li> <li>Learns naming conventions</li> </ul>"},{"location":"getting-started/quickstart/#step-5-query","title":"Step 5: Query!","text":"<pre><code>result = await agent.query(\"How many orders were placed last month?\")\n\nif result[\"success\"]:\n    print(f\"SQL: {result['sql']}\")\n    print(f\"Rows: {result['row_count']}\")\n    print(f\"Data: {result['data']}\")\nelse:\n    print(f\"Error: {result['error']}\")\n</code></pre>"},{"location":"getting-started/quickstart/#response-structure","title":"Response Structure","text":"<pre><code>{\n    \"success\": True,\n    \"sql\": \"SELECT COUNT(*) FROM orders WHERE ...\",\n    \"data\": [{\"count\": 1234}],\n    \"row_count\": 1,\n    \"iterations\": 1,  # Self-correction attempts\n    \"problem_type\": \"counting\",\n    \"execution_time_ms\": 145.5,\n}\n</code></pre>"},{"location":"getting-started/quickstart/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nimport os\nfrom dotenv import load_dotenv\n\nfrom src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\nfrom src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\n\nload_dotenv()\n\nasync def main():\n    # 1. Setup LLM\n    llm = AzureOpenAIClient(AzureOpenAIConfig(\n        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n        azure_deployment=\"gpt-4o\",\n    ))\n\n    # 2. Create agent\n    agent = MetaAgent(llm_client=llm)\n\n    # 3. Connect to database\n    db = MSSQLAdapter(ConnectionConfig(\n        name=\"my_db\",\n        db_type=DatabaseType.MSSQL,\n        host=os.getenv(\"DB_HOST\"),\n        database=os.getenv(\"DB_NAME\"),\n        username=os.getenv(\"DB_USER\"),\n        password=os.getenv(\"DB_PASSWORD\"),\n    ))\n    await db.connect()\n\n    # 4. Connect agent (auto-discovers everything)\n    stats = await agent.connect(db_executor=db.execute)\n    print(f\"Connected: {stats['tables']} tables\")\n\n    # 5. Query\n    result = await agent.query(\"Show top 10 customers by revenue\")\n\n    if result[\"success\"]:\n        print(f\"\\nSQL:\\n{result['sql']}\\n\")\n        print(f\"Results ({result['row_count']} rows):\")\n        for row in result[\"data\"]:\n            print(f\"  {row}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/quickstart/#optional-add-memory-storage","title":"Optional: Add Memory Storage","text":"<p>The MetaAgent uses a simple JSON file by default (<code>~/.vanna/meta_agent.json</code>). For advanced scenarios with semantic search and persistent storage, pass a <code>MemoryManager</code> to the agent:</p>"},{"location":"getting-started/quickstart/#complete-example-with-memory-stores","title":"Complete Example with Memory Stores","text":"<pre><code>import asyncio\nfrom src.intelligence.meta_agent import MetaAgent\nfrom src.llm.azure_openai_client import AzureOpenAIClient, AzureOpenAIConfig\nfrom src.database.multi_db import MSSQLAdapter, ConnectionConfig, DatabaseType\nfrom src.memory.manager import MemoryManager, MemoryConfig\nfrom src.memory.stores import SQLiteMemoryStore, ChromaMemoryStore\nfrom src.memory.stores.sqlite_store import SQLiteConfig\nfrom src.memory.stores.chroma_store import ChromaConfig\n\nasync def main():\n    # 1. Setup LLM\n    llm = AzureOpenAIClient(AzureOpenAIConfig(\n        api_key=\"your-key\",\n        azure_endpoint=\"https://your-endpoint.openai.azure.com\",\n        azure_deployment=\"gpt-4o\",\n    ))\n\n    # 2. Setup memory stores\n    sql_store = SQLiteMemoryStore(SQLiteConfig(db_path=\"./memories.db\"))\n    vector_store = ChromaMemoryStore(ChromaConfig(path=\"./chroma_data\"))\n    await sql_store.connect()\n    await vector_store.connect()\n\n    # 3. Create MemoryManager\n    memory = MemoryManager(\n        config=MemoryConfig(enable_sql=True, enable_vector=True),\n        sql_store=sql_store,\n        vector_store=vector_store,\n    )\n\n    # 4. Create agent WITH memory_manager\n    agent = MetaAgent(\n        llm_client=llm,\n        memory_manager=memory,  # &lt;-- Pass memory here!\n    )\n\n    # 5. Connect to database\n    db = MSSQLAdapter(ConnectionConfig(...))\n    await db.connect()\n    await agent.connect(db_executor=db.execute)\n\n    # 6. Query - agent now stores/retrieves from memory stores!\n    result = await agent.query(\"Show top customers by revenue\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/quickstart/#store-options","title":"Store Options","text":"SQLite (No Server)ChromaDB (Local Vector)Qdrant (Production Vector)OpenSearch (Hybrid) <pre><code>from src.memory.stores import SQLiteMemoryStore\nfrom src.memory.stores.sqlite_store import SQLiteConfig\nfrom src.memory.manager import MemoryManager, MemoryConfig\n\n# Create store\nstore = SQLiteMemoryStore(SQLiteConfig(db_path=\"./memories.db\"))\nawait store.connect()\n\n# Use with MemoryManager\nmemory = MemoryManager(\n    config=MemoryConfig(enable_sql=True),\n    sql_store=store,\n)\n</code></pre> <pre><code>from src.memory.stores import ChromaMemoryStore\nfrom src.memory.stores.chroma_store import ChromaConfig\n\nstore = ChromaMemoryStore(ChromaConfig(\n    path=\"./chroma_data\",\n    collection_name=\"sql_memories\",\n))\nawait store.connect()\n</code></pre> <pre><code>from src.memory.stores import QdrantMemoryStore\nfrom src.memory.stores.qdrant_store import QdrantConfig\n\nstore = QdrantMemoryStore(QdrantConfig(\n    host=\"localhost\",\n    port=6333,\n    collection_name=\"sql_memories\",\n))\nawait store.connect()\n</code></pre> <pre><code>from src.memory.stores import OpenSearchMemoryStore\nfrom src.memory.stores.opensearch_store import OpenSearchConfig\n\nstore = OpenSearchMemoryStore(OpenSearchConfig(\n    hosts=[\"https://localhost:9200\"],\n    index_name=\"sql_memories\",\n    username=\"admin\",\n    password=\"admin\",\n))\nawait store.connect()\n</code></pre> <p>See Storage Backends for full documentation.</p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Auto-Learning - Train the agent on your database</li> <li>Query Processing - How queries work</li> <li>Storage Backends - Configure memory storage</li> <li>API Reference - Full API documentation</li> </ul>"},{"location":"guide/auto-discovery/","title":"Auto-Discovery","text":"<p>How the agent automatically discovers your database.</p>"},{"location":"guide/auto-discovery/#overview","title":"Overview","text":"<p>When you call <code>agent.connect()</code>, the agent:</p> <ol> <li>Probes database to detect SQL dialect</li> <li>Discovers schema (tables, columns, types)</li> <li>Analyzes relationships between tables</li> <li>Learns naming conventions</li> <li>Generates insights about the database</li> </ol> <pre><code>stats = await agent.connect(db_executor=db.execute)\n# {\n#     \"dialect\": \"mssql\",\n#     \"tables\": 25,\n#     \"schema_insights\": 19,\n# }\n</code></pre>"},{"location":"guide/auto-discovery/#dialect-detection","title":"Dialect Detection","text":"<p>The agent runs probe queries to detect the SQL dialect:</p> <pre><code>probes = [\n    (\"SELECT TOP 1 1 AS test\", \"TOP syntax\"),      # MSSQL\n    (\"SELECT 1 AS test LIMIT 1\", \"LIMIT syntax\"),  # PostgreSQL/MySQL\n    (\"SELECT GETDATE()\", \"GETDATE function\"),      # MSSQL\n    (\"SELECT NOW()\", \"NOW function\"),              # PostgreSQL/MySQL\n]\n</code></pre> <p>Based on which queries succeed/fail, the LLM determines the dialect:</p> Dialect TOP LIMIT GETDATE NOW MS SQL :material-check: :material-close: :material-check: :material-close: PostgreSQL :material-close: :material-check: :material-close: :material-check: MySQL :material-close: :material-check: :material-close: :material-check: SQLite :material-close: :material-check: :material-close: :material-close:"},{"location":"guide/auto-discovery/#schema-discovery","title":"Schema Discovery","text":"<p>The agent queries <code>INFORMATION_SCHEMA</code> to discover:</p> <ul> <li>Tables</li> <li>Columns and data types</li> <li>Primary keys</li> <li>Foreign key relationships</li> </ul> <pre><code>-- Tables\nSELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\nWHERE TABLE_TYPE = 'BASE TABLE'\n\n-- Columns\nSELECT COLUMN_NAME, DATA_TYPE\nFROM INFORMATION_SCHEMA.COLUMNS\nWHERE TABLE_NAME = 'users'\n</code></pre>"},{"location":"guide/auto-discovery/#schema-analysis","title":"Schema Analysis","text":"<p>The LLM analyzes the schema and generates insights:</p> <pre><code># Example insights generated:\ninsights = [\n    \"- Users table has email, name, created_at columns\",\n    \"- Orders joins to Customers via customer_id\",\n    \"- Products table uses decimal for price\",\n    \"- Naming convention: PascalCase for tables\",\n]\n</code></pre> <p>These insights are stored and used in future queries.</p>"},{"location":"guide/auto-discovery/#what-gets-learned","title":"What Gets Learned","text":"Category Example Tables <code>users</code>, <code>orders</code>, <code>products</code> Columns <code>id</code>, <code>name</code>, <code>created_at</code> Types <code>varchar</code>, <code>int</code>, <code>datetime</code> Relationships <code>orders.customer_id \u2192 customers.id</code> Naming PascalCase, snake_case Dialect TOP vs LIMIT, date functions"},{"location":"guide/auto-discovery/#manual-override","title":"Manual Override","text":"<p>You can provide hints:</p> <pre><code>stats = await agent.connect(\n    db_executor=db.execute,\n    driver=\"mssql\",  # Hint for dialect\n)\n</code></pre>"},{"location":"guide/auto-learning/","title":"Auto-Learning","text":"<p>Self-training on your database.</p>"},{"location":"guide/auto-learning/#overview","title":"Overview","text":"<p>The <code>auto_learn()</code> method trains the agent automatically:</p> <ol> <li>Explores domain - Understands what the database is about</li> <li>Generates questions - Creates test questions for your data</li> <li>Tests questions - Runs queries and learns from results</li> <li>Targets weak areas - Improves where it failed</li> </ol> <pre><code>results = await agent.auto_learn(intensity=\"medium\")\n</code></pre>"},{"location":"guide/auto-learning/#dynamic-question-calculation","title":"Dynamic Question Calculation","text":"<p>Questions are calculated based on your database complexity:</p> <pre><code>Formula: (tables \u00d7 2) + (columns \u00f7 10) + (relationships \u00f7 3) \u00d7 multiplier\n</code></pre>"},{"location":"guide/auto-learning/#intensity-levels","title":"Intensity Levels","text":"Level Multiplier Use Case <code>light</code> 0.3\u00d7 Quick validation <code>medium</code> 0.6\u00d7 Balanced coverage <code>heavy</code> 1.0\u00d7 Comprehensive <code>exhaustive</code> 1.5\u00d7 Deep training"},{"location":"guide/auto-learning/#example-calculations","title":"Example Calculations","text":"Database Tables Columns Light Medium Heavy Tiny 2 4 3 3 5 Small 5 17 4 8 14 Medium 15 68 13 27 45 Large 40 334 39 78 100 Very Large 80 880 82 100 100 <p>Bounds</p> <ul> <li>Minimum: 3 questions</li> <li>Maximum: 100 questions</li> </ul>"},{"location":"guide/auto-learning/#learning-process","title":"Learning Process","text":"<pre><code>graph TB\n    A[Explore Domain] --&gt; B[Generate Questions]\n    B --&gt; C[Test Questions]\n    C --&gt; D{Success?}\n    D --&gt;|Yes| E[Store Solution]\n    D --&gt;|No| F[Analyze Failure]\n    F --&gt; G[Target Weak Areas]\n    G --&gt; C\n    E --&gt; H[Save Knowledge]</code></pre>"},{"location":"guide/auto-learning/#step-1-explore-domain","title":"Step 1: Explore Domain","text":"<pre><code># LLM analyzes schema\ndomain = await agent._llm_explore_domain()\n# {\n#     \"domain\": \"ecommerce\",\n#     \"entities\": \"customers, orders, products\",\n#     \"relationships\": \"orders \u2192 customers\",\n# }\n</code></pre>"},{"location":"guide/auto-learning/#step-2-generate-questions","title":"Step 2: Generate Questions","text":"<p>The LLM generates diverse questions:</p> <ul> <li>Simple counts (\"How many X?\")</li> <li>Listings (\"Show all X\")</li> <li>Filtering (\"Find X where Y\")</li> <li>Aggregations (\"Total/Average of X\")</li> <li>Rankings (\"Top 10 X by Y\")</li> <li>Joins (\"X with their Y\")</li> </ul>"},{"location":"guide/auto-learning/#step-3-test-learn","title":"Step 3: Test &amp; Learn","text":"<pre><code>for question in questions:\n    result = await agent.query(question)\n\n    if result[\"success\"]:\n        # Store successful pattern\n        store_solution(question, result[\"sql\"])\n    else:\n        # Analyze failure\n        learn_from_failure(question, result[\"error\"])\n</code></pre>"},{"location":"guide/auto-learning/#step-4-target-weak-areas","title":"Step 4: Target Weak Areas","text":"<p>If failures occur, the agent generates simpler questions to learn the correct patterns.</p>"},{"location":"guide/auto-learning/#results","title":"Results","text":"<pre><code>results = await agent.auto_learn(intensity=\"medium\")\n\nprint(f\"Domain: {results['domain']}\")\nprint(f\"Questions: {results['questions_tested']}\")\nprint(f\"Success rate: {results['success_rate']*100:.0f}%\")\n</code></pre>"},{"location":"guide/auto-learning/#return-structure","title":"Return Structure","text":"<pre><code>{\n    \"domain\": \"ecommerce\",\n    \"questions_generated\": 27,\n    \"questions_tested\": 27,\n    \"successes\": 25,\n    \"failures\": 2,\n    \"success_rate\": 0.926,\n    \"learnings\": [...],\n    \"schema_stats\": {\n        \"tables\": 15,\n        \"total_columns\": 68,\n    },\n    \"target_questions\": 27,\n    \"intensity\": \"medium\",\n}\n</code></pre>"},{"location":"guide/auto-learning/#what-gets-learned","title":"What Gets Learned","text":"Category Example Successful SQL <code>SELECT COUNT(*) FROM users</code> Error patterns <code>LIMIT doesn't work in MSSQL</code> Name corrections <code>\"categories\" \u2192 \"Category\"</code> Table mappings <code>\"products\" \u2192 \"product_items\"</code> Fix strategies <code>TRY_CAST for conversion errors</code>"},{"location":"guide/query-processing/","title":"Query Processing","text":"<p>How the agent processes natural language queries.</p>"},{"location":"guide/query-processing/#the-think-research-design-execute-learn-loop","title":"The THINK-RESEARCH-DESIGN-EXECUTE-LEARN Loop","text":"<p>Every query goes through 5 phases:</p> <pre><code>graph LR\n    A[THINK] --&gt; B[RESEARCH]\n    B --&gt; C[DESIGN]\n    C --&gt; D[EXECUTE]\n    D --&gt; E[LEARN]</code></pre>"},{"location":"guide/query-processing/#phase-1-think","title":"Phase 1: THINK","text":"<p>Analyze the question and classify the problem.</p> <pre><code># LLM analyzes:\n# - What is being asked?\n# - What entities are involved?\n# - What operations are needed?\n# - What might be challenging?\n</code></pre> <p>Output: <pre><code>{\n    \"type\": \"aggregation_with_filter\",\n    \"entities\": [\"orders\", \"customers\"],\n    \"operations\": [\"COUNT\", \"GROUP BY\", \"WHERE\"],\n}\n</code></pre></p>"},{"location":"guide/query-processing/#phase-2-research","title":"Phase 2: RESEARCH","text":"<p>Find similar problems that worked before.</p> <pre><code># Search knowledge base:\n# - Similar successful solutions\n# - Relevant failures to avoid\n# - Fix strategies that worked\n</code></pre> <p>Uses: - <code>successful_solutions</code> - What SQL worked - <code>failed_attempts</code> - What to avoid - <code>fix_strategies</code> - How to fix errors</p>"},{"location":"guide/query-processing/#phase-3-design","title":"Phase 3: DESIGN","text":"<p>Create a dynamic, custom prompt for THIS specific problem.</p> <pre><code># The prompt includes:\n# - Problem analysis\n# - Schema context\n# - Similar examples\n# - Failures to avoid\n# - Name corrections\n# - Dialect specifics\n</code></pre> <p>Dynamic Prompts</p> <p>No fixed templates. Every prompt is generated based on the specific problem and learned knowledge.</p>"},{"location":"guide/query-processing/#phase-4-execute","title":"Phase 4: EXECUTE","text":"<p>Run the SQL with intelligent error handling.</p> <pre><code>for iteration in range(4):\n    try:\n        data = await db_executor(sql)\n        return {\"success\": True, \"data\": data}\n    except Exception as e:\n        sql = await self._llm_fix_error(sql, error)\n</code></pre> <p>Self-Correction: - Up to 4 attempts - LLM analyzes error - Searches for correct names - Applies learned fixes</p>"},{"location":"guide/query-processing/#phase-5-learn","title":"Phase 5: LEARN","text":"<p>Store the outcome for future queries.</p> On SuccessOn Failure <pre><code># Store successful solution\nknowledge.successful_solutions.append({\n    \"question\": question,\n    \"sql\": sql,\n    \"problem_type\": problem_type,\n})\n\n# If corrections worked, store fix strategy\nif iterations &gt; 1:\n    knowledge.fix_strategies.append({\n        \"error_type\": error,\n        \"strategy\": fix_applied,\n        \"worked\": True,\n    })\n</code></pre> <pre><code># Analyze failure\nanalysis = await llm.analyze_failure(question, error)\n\n# Extract name corrections\nif \"invalid object\" in error:\n    wrong_name = extract_wrong_name(error)\n    correct_name = search_database(wrong_name)\n    knowledge.name_corrections[wrong_name] = correct_name\n\n# Store for future reference\nknowledge.failed_attempts.append({\n    \"question\": question,\n    \"error\": error,\n    \"analysis\": analysis,\n})\n</code></pre>"},{"location":"guide/query-processing/#example-flow","title":"Example Flow","text":"<p>Question: \"How many orders per customer?\"</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 THINK                                                        \u2502\n\u2502 Type: aggregation                                           \u2502\n\u2502 Entities: orders, customers                                 \u2502\n\u2502 Operations: COUNT, GROUP BY                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 RESEARCH                                                     \u2502\n\u2502 Found: \"orders by user\" \u2192 SELECT user_id, COUNT(*)          \u2502\n\u2502 Avoid: LIMIT syntax (this is MSSQL)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DESIGN                                                       \u2502\n\u2502 Apply: name_corrections[\"customer\"] \u2192 \"customer_id\"         \u2502\n\u2502 Apply: dialect = MSSQL (use TOP not LIMIT)                  \u2502\n\u2502 Generate: Dynamic prompt with all context                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 EXECUTE                                                      \u2502\n\u2502 SQL: SELECT customer_id, COUNT(*) as order_count            \u2502\n\u2502      FROM orders GROUP BY customer_id                        \u2502\n\u2502 Result: [{\"customer_id\": 1, \"order_count\": 5}, ...]         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 LEARN                                                        \u2502\n\u2502 Store: successful_solutions.append(...)                      \u2502\n\u2502 Save: ~/.vanna/meta_agent.json                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guide/self-healing/","title":"Self-Healing","text":"<p>How the agent automatically fixes errors.</p>"},{"location":"guide/self-healing/#overview","title":"Overview","text":"<p>When SQL execution fails, the agent:</p> <ol> <li>Analyzes the error with LLM</li> <li>Searches database for correct names</li> <li>Learns corrections for future queries</li> <li>Retries with fixed SQL (up to 4 attempts)</li> </ol>"},{"location":"guide/self-healing/#error-handling-flow","title":"Error Handling Flow","text":"<pre><code>graph TB\n    A[Execute SQL] --&gt; B{Success?}\n    B --&gt;|Yes| C[Return Results]\n    B --&gt;|No| D[Analyze Error]\n    D --&gt; E[Search for Fix]\n    E --&gt; F[Apply Correction]\n    F --&gt; G{Attempt &lt; 4?}\n    G --&gt;|Yes| A\n    G --&gt;|No| H[Return Failure]\n    F --&gt; I[Store Learning]</code></pre>"},{"location":"guide/self-healing/#name-correction","title":"Name Correction","text":"<p>When an \"invalid object name\" error occurs:</p> <pre><code># Error: \"Invalid object name 'Categories'\"\n\n# Step 1: Extract wrong name\nwrong_name = \"Categories\"\n\n# Step 2: Search database for correct name\nall_tables = await db.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\")\n\n# Step 3: LLM finds correct name\ncorrect_name = \"Category\"  # LLM matches by similarity\n\n# Step 4: Store correction\nknowledge.name_corrections[\"categories\"] = \"Category\"\n</code></pre> <p>Next time: <pre><code># Query: \"Show all categories\"\n# Agent applies correction BEFORE generating SQL\n# \u2192 \"SELECT * FROM Category\" (correct!)\n</code></pre></p>"},{"location":"guide/self-healing/#table-relationship-learning","title":"Table Relationship Learning","text":"<p>When a query fails because the wrong table was used:</p> <pre><code># Failed SQL: SELECT category FROM Products\n# Error: \"Invalid column name 'category'\"\n\n# LLM analyzes:\n# - Question asked about \"categories\"\n# - Products table doesn't have category column\n# - Categories are in the \"Category\" table\n\n# Store learning:\nknowledge.table_relationships[\"categories\"] = \"Category\"\n</code></pre>"},{"location":"guide/self-healing/#fix-strategies","title":"Fix Strategies","text":"<p>The agent learns which fixes work:</p> Error Type Strategy Example Invalid object Search for correct name <code>\"Categories\" \u2192 \"Category\"</code> Conversion error Use TRY_CAST <code>TRY_CAST(col AS INT)</code> NULL issues Add ISNULL <code>ISNULL(col, 0)</code> Syntax error Dialect-specific fix <code>TOP</code> vs <code>LIMIT</code>"},{"location":"guide/self-healing/#retry-logic","title":"Retry Logic","text":"<pre><code>for iteration in range(4):\n    try:\n        data = await db_executor(sql)\n        return {\"success\": True, \"iterations\": iteration + 1}\n\n    except Exception as e:\n        if iteration &lt; 3:\n            # Different strategy each attempt\n            if iteration == 0:\n                strategy = \"Fix syntax directly\"\n            elif iteration == 1:\n                strategy = \"Use type conversion\"\n            elif iteration == 2:\n                strategy = \"Filter problematic data\"\n            else:\n                strategy = \"Completely rethink approach\"\n\n            sql = await llm_fix_error(sql, error, strategy)\n</code></pre>"},{"location":"guide/self-healing/#example-self-healing-in-action","title":"Example: Self-Healing in Action","text":"<p>Question: \"Show category sales\"</p> <p>Attempt 1: <pre><code>SELECT * FROM Categories\n-- Error: Invalid object name 'Categories'\n</code></pre></p> <p>Agent learns: <code>Categories \u2192 Category</code></p> <p>Attempt 2: <pre><code>SELECT * FROM Category\n-- Success!\n</code></pre></p> <p>Future queries: <pre><code>-- \"Show categories\" \u2192 automatically uses \"Category\"\nSELECT * FROM Category\n</code></pre></p>"},{"location":"guide/self-healing/#what-gets-learned","title":"What Gets Learned","text":"Learning Type Storage Example Name corrections <code>name_corrections</code> <code>{\"categorie\": \"Category\"}</code> Table mappings <code>table_relationships</code> <code>{\"products\": \"ProductItems\"}</code> Column mappings <code>column_mappings</code> <code>{\"revenue\": \"TotalAmount\"}</code> Fix strategies <code>fix_strategies</code> <code>{\"conversion\": \"TRY_CAST\"}</code> Dialect rules <code>dialect_learnings</code> <code>\"Use TOP not LIMIT\"</code>"},{"location":"memory/architecture/","title":"Memory Architecture","text":"<p>Hybrid memory system for intelligent knowledge management.</p>"},{"location":"memory/architecture/#overview","title":"Overview","text":"<pre><code>graph TB\n    subgraph Memory[\"Memory Manager\"]\n        Graph[Graph Store]\n        Vector[Vector Store]\n        SQL[SQL Store]\n    end\n\n    subgraph ECL[\"ECL Pipeline\"]\n        Extract[Extract]\n        Cognify[Cognify]\n        Load[Load]\n        Extract --&gt; Cognify --&gt; Load\n    end\n\n    Input[New Memory] --&gt; ECL\n    ECL --&gt; Memory</code></pre>"},{"location":"memory/architecture/#three-storage-backends","title":"Three Storage Backends","text":"Store Purpose Data Graph Entity relationships Nodes, edges, traversal Vector Semantic similarity Embeddings, cosine distance SQL Structured persistence Tables, queries"},{"location":"memory/architecture/#memory-hierarchy","title":"Memory Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  SESSION  \u2502 Current conversation    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  USER     \u2502 User-specific prefs     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  ENTITY   \u2502 Facts about entities    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  GLOBAL   \u2502 Shared knowledge        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Higher levels override lower levels during retrieval.</p>"},{"location":"memory/ecl-pipeline/","title":"ECL Pipeline","text":"<p>Extract, Cognify, Load - the memory processing pipeline.</p>"},{"location":"memory/ecl-pipeline/#pipeline-stages","title":"Pipeline Stages","text":"<pre><code>graph LR\n    A[Extract] --&gt; B[Cognify]\n    B --&gt; C[Load]</code></pre>"},{"location":"memory/ecl-pipeline/#extract","title":"Extract","text":"<p>Parse raw content and prepare for processing.</p> <pre><code>memory = await manager.add(\n    content=\"SELECT * FROM users\",\n    memory_type=MemoryType.QUERY_PATTERN,\n)\n</code></pre> <ul> <li>Parse content</li> <li>Extract metadata</li> <li>Deduplication check</li> </ul>"},{"location":"memory/ecl-pipeline/#cognify","title":"Cognify","text":"<p>Transform into structured knowledge.</p> <pre><code>memory = await manager.cognify(memory)\n</code></pre> <ul> <li>Generate embeddings</li> <li>Extract entities</li> <li>Find relationships</li> </ul>"},{"location":"memory/ecl-pipeline/#load","title":"Load","text":"<p>Persist to storage backends.</p> <pre><code>await manager.store(memory)\n</code></pre> <ul> <li>Store in Graph (relationships)</li> <li>Store in Vector (embeddings)</li> <li>Store in SQL (persistence)</li> </ul>"},{"location":"memory/ecl-pipeline/#complete-pipeline","title":"Complete Pipeline","text":"<pre><code># Run all stages automatically\nmemory = await manager.ingest(\n    content=\"SELECT COUNT(*) FROM users\",\n    memory_type=MemoryType.QUERY_PATTERN,\n)\n</code></pre>"},{"location":"memory/stores/","title":"Memory Stores","text":"<p>Agentic SQL provides multiple storage backends for the memory system. Each store has different strengths and use cases.</p>"},{"location":"memory/stores/#overview","title":"Overview","text":"Store Type Use Case Installation SQLite File-based Simple deployments, no server needed <code>pip install agentic-sql[sqlite]</code> ChromaDB Vector Semantic search, local/embedded <code>pip install agentic-sql[vector]</code> Qdrant Vector High-performance vector search <code>pip install agentic-sql[qdrant]</code> OpenSearch Hybrid Vector + full-text search <code>pip install agentic-sql[opensearch]</code> Neo4j Graph Entity relationships <code>pip install agentic-sql[graph]</code> <p>Install all memory backends: <pre><code>pip install agentic-sql[memory-all]\n</code></pre></p>"},{"location":"memory/stores/#sqlite-store","title":"SQLite Store","text":"<p>Lightweight, file-based storage that requires no external server. Best for simple deployments and development.</p>"},{"location":"memory/stores/#installation","title":"Installation","text":"<pre><code>pip install agentic-sql[sqlite]\n</code></pre>"},{"location":"memory/stores/#usage","title":"Usage","text":"<pre><code>from memory.stores import SQLiteMemoryStore\nfrom memory.stores.sqlite_store import SQLiteConfig\n\nconfig = SQLiteConfig(\n    db_path=\"./memories.db\"\n)\n\nstore = SQLiteMemoryStore(config)\nawait store.connect()\n\n# Store a memory\nawait store.store(memory)\n\n# Retrieve with full-text search\nresults = await store.retrieve(\"user preferences\", limit=10)\n\n# Get by type\nfacts = await store.get_by_type(MemoryType.FACT, limit=50)\n</code></pre>"},{"location":"memory/stores/#features","title":"Features","text":"<ul> <li>No external server required</li> <li>FTS5 full-text search support</li> <li>WAL mode for concurrent access</li> <li>Automatic index creation</li> </ul>"},{"location":"memory/stores/#chromadb-store","title":"ChromaDB Store","text":"<p>Open-source embedding database with automatic embedding support. Good for local/embedded vector search.</p>"},{"location":"memory/stores/#installation_1","title":"Installation","text":"<pre><code>pip install agentic-sql[vector]\n</code></pre>"},{"location":"memory/stores/#usage_1","title":"Usage","text":"<pre><code>from memory.stores import ChromaMemoryStore\nfrom memory.stores.chroma_store import ChromaConfig\n\nconfig = ChromaConfig(\n    path=\"./chroma_data\",\n    collection_name=\"agentic_sql_memories\",\n    distance_fn=\"cosine\",  # cosine, l2, ip\n)\n\nstore = ChromaMemoryStore(config)\nawait store.connect()\n\n# Store with embedding\nmemory.embedding = [0.1, 0.2, ...]  # 1536-dim vector\nawait store.store(memory)\n\n# Semantic search\nresults = await store.retrieve(\n    query=\"database performance\",\n    query_vector=embedding,  # Optional pre-computed vector\n    limit=10,\n)\n</code></pre>"},{"location":"memory/stores/#client-server-mode","title":"Client-Server Mode","text":"<pre><code>config = ChromaConfig(\n    host=\"localhost\",\n    port=8000,\n    collection_name=\"memories\",\n)\n</code></pre>"},{"location":"memory/stores/#features_1","title":"Features","text":"<ul> <li>Simple setup, no server required</li> <li>Persistent local storage</li> <li>Automatic embedding (optional)</li> <li>Metadata filtering</li> </ul>"},{"location":"memory/stores/#qdrant-store","title":"Qdrant Store","text":"<p>High-performance vector database optimized for similarity search with filtering.</p>"},{"location":"memory/stores/#installation_2","title":"Installation","text":"<pre><code>pip install agentic-sql[qdrant]\n</code></pre>"},{"location":"memory/stores/#usage_2","title":"Usage","text":"<pre><code>from memory.stores import QdrantMemoryStore\nfrom memory.stores.qdrant_store import QdrantConfig\n\nconfig = QdrantConfig(\n    host=\"localhost\",\n    port=6333,\n    collection_name=\"agentic_sql_memories\",\n    vector_size=1536,\n    distance=\"Cosine\",  # Cosine, Euclid, Dot\n    on_disk=False,  # Store vectors on disk for large collections\n)\n\nstore = QdrantMemoryStore(config)\nawait store.connect()\n\n# Vector search with filtering\nresults = await store.retrieve(\n    query=\"\",\n    query_vector=embedding,\n    memory_type=MemoryType.SEMANTIC,\n    score_threshold=0.7,\n    limit=10,\n)\n</code></pre>"},{"location":"memory/stores/#multi-tenancy","title":"Multi-Tenancy","text":"<pre><code>config = QdrantConfig(\n    host=\"localhost\",\n    port=6333,\n    collection_name=\"memories\",\n    # Multi-tenancy options\n    namespace=\"production\",      # Logical namespace\n    tenant_id=\"customer_123\",    # Tenant isolation\n    group_id=\"project_abc\",      # Group/project isolation\n)\n\nstore = QdrantMemoryStore(config)\nawait store.connect()\n\n# Search within namespace/tenant (auto-filtered)\nresults = await store.retrieve(query_vector=embedding, limit=10)\n\n# Override filters per query\nresults = await store.retrieve(\n    query_vector=embedding,\n    namespace=\"staging\",\n    tenant_id=\"customer_456\",\n)\n</code></pre>"},{"location":"memory/stores/#cloud-deployment","title":"Cloud Deployment","text":"<pre><code>config = QdrantConfig(\n    url=\"https://your-cluster.qdrant.io\",  # Full URL for cloud\n    api_key=\"your-api-key\",\n    collection_name=\"memories\",\n)\n</code></pre>"},{"location":"memory/stores/#features_2","title":"Features","text":"<ul> <li>High-performance vector search</li> <li>Multi-tenancy (namespace, tenant_id, group_id)</li> <li>Payload filtering</li> <li>On-disk storage option</li> <li>HNSW indexing</li> <li>Cloud or self-hosted</li> </ul>"},{"location":"memory/stores/#opensearch-store","title":"OpenSearch Store","text":"<p>Enterprise-grade search with both vector and full-text capabilities. Best for hybrid search scenarios.</p>"},{"location":"memory/stores/#installation_3","title":"Installation","text":"<pre><code>pip install agentic-sql[opensearch]\n</code></pre>"},{"location":"memory/stores/#usage_3","title":"Usage","text":"<pre><code>from memory.stores import OpenSearchMemoryStore\nfrom memory.stores.opensearch_store import OpenSearchConfig\n\nconfig = OpenSearchConfig(\n    hosts=[\"https://localhost:9200\"],\n    index_name=\"agentic_sql_memories\",\n    username=\"admin\",\n    password=\"admin\",\n    vector_dimension=1536,\n    use_ssl=True,\n    verify_certs=False,\n)\n\nstore = OpenSearchMemoryStore(config)\nawait store.connect()\n\n# Hybrid search (vector + text)\nresults = await store.retrieve(\n    query=\"database optimization tips\",\n    query_vector=embedding,\n    use_hybrid=True,  # Combine k-NN with BM25\n    limit=10,\n)\n\n# Pure text search\ntext_results = await store.search_text(\n    query=\"index performance\",\n    limit=10,\n)\n</code></pre>"},{"location":"memory/stores/#multi-tenancy_1","title":"Multi-Tenancy","text":"<pre><code>config = OpenSearchConfig(\n    hosts=[\"https://localhost:9200\"],\n    index_name=\"memories\",\n    index_prefix=\"prod_\",         # Index becomes \"prod_memories\"\n    # Multi-tenancy options\n    namespace=\"production\",       # Stored as document field\n    tenant_id=\"customer_123\",     # Stored as document field\n    group_id=\"project_abc\",       # Stored as document field\n    # Sharding\n    number_of_shards=3,\n    number_of_replicas=1,\n)\n\nstore = OpenSearchMemoryStore(config)\nawait store.connect()\n\n# Queries auto-filter by namespace/tenant/group\nresults = await store.retrieve(query=\"search term\", limit=10)\n\n# Override filters per query\nresults = await store.retrieve(\n    query=\"search term\",\n    namespace=\"staging\",\n    tenant_id=\"customer_456\",\n)\n\n# Count within tenant\ncount = await store.count(tenant_id=\"customer_123\")\n</code></pre>"},{"location":"memory/stores/#hnsw-parameters","title":"HNSW Parameters","text":"<pre><code>config = OpenSearchConfig(\n    ef_construction=512,  # Higher = better recall, slower indexing\n    m=16,  # Higher = better recall, more memory\n)\n</code></pre>"},{"location":"memory/stores/#features_3","title":"Features","text":"<ul> <li>k-NN vector similarity search</li> <li>BM25 full-text search</li> <li>Hybrid search combining both</li> <li>Multi-tenancy (namespace, tenant_id, group_id)</li> <li>Index prefixing for environments</li> <li>Rich filtering capabilities</li> <li>Scalable and distributed</li> </ul>"},{"location":"memory/stores/#neo4j-store","title":"Neo4j Store","text":"<p>Graph database for relationship-based memory with traversal capabilities.</p>"},{"location":"memory/stores/#installation_4","title":"Installation","text":"<pre><code>pip install agentic-sql[graph]\n</code></pre>"},{"location":"memory/stores/#usage_4","title":"Usage","text":"<pre><code>from memory.stores import Neo4jMemoryStore\nfrom memory.stores.neo4j_store import Neo4jConfig\n\nconfig = Neo4jConfig(\n    uri=\"bolt://localhost:7687\",\n    username=\"neo4j\",\n    password=\"password\",\n    database=\"neo4j\",\n)\n\nstore = Neo4jMemoryStore(config)\nawait store.connect()\n\n# Store with relationships\nmemory.metadata = {\n    \"relationships\": [\n        {\"target_id\": \"uuid-1\", \"type\": \"relates_to\"},\n        {\"target_id\": \"uuid-2\", \"type\": \"depends_on\"},\n    ]\n}\nawait store.store(memory)\n\n# Graph traversal retrieval\nresults = await store.retrieve(\n    query=\"uuid-of-starting-node\",\n    depth=2,  # Traverse up to 2 hops\n    limit=10,\n)\n</code></pre>"},{"location":"memory/stores/#multi-tenancy_2","title":"Multi-Tenancy","text":"<pre><code>config = Neo4jConfig(\n    uri=\"bolt://localhost:7687\",\n    username=\"neo4j\",\n    password=\"password\",\n    database=\"neo4j\",\n    # Multi-tenancy options\n    namespace=\"production\",      # Added as node label (NS_production)\n    tenant_id=\"customer_123\",    # Stored as node property\n    group_id=\"project_abc\",      # Stored as node property\n    node_label=\"Memory\",         # Base label for nodes\n    use_namespace_label=True,    # Add namespace as additional label\n)\n\nstore = Neo4jMemoryStore(config)\nawait store.connect()\n\n# Nodes are labeled: Memory:NS_production\n# Queries auto-filter by namespace/tenant/group\nresults = await store.retrieve(query=\"search term\", limit=10)\n\n# Override filters per query\nresults = await store.retrieve(\n    query=\"search term\",\n    namespace=\"staging\",\n    tenant_id=\"customer_456\",\n)\n</code></pre>"},{"location":"memory/stores/#features_4","title":"Features","text":"<ul> <li>Entity relationships</li> <li>Multi-tenancy (namespace as labels, tenant/group as properties)</li> <li>Graph traversal for context expansion</li> <li>Cypher query support</li> <li>Automatic index creation</li> <li>Relationship types</li> </ul>"},{"location":"memory/stores/#combining-stores","title":"Combining Stores","text":"<p>You can use multiple stores together for different purposes:</p> <pre><code>from memory.manager import MemoryManager\n\n# Use SQLite for quick access, Qdrant for semantic search\nsqlite_store = SQLiteMemoryStore(SQLiteConfig())\nqdrant_store = QdrantMemoryStore(QdrantConfig())\n\nawait sqlite_store.connect()\nawait qdrant_store.connect()\n\n# Store in both\nasync def store_memory(memory):\n    await sqlite_store.store(memory)\n    if memory.embedding:\n        await qdrant_store.store(memory)\n\n# Quick lookup from SQLite\nfacts = await sqlite_store.get_by_type(MemoryType.FACT)\n\n# Semantic search from Qdrant\nsimilar = await qdrant_store.retrieve(\n    query=\"\",\n    query_vector=embedding,\n)\n</code></pre>"},{"location":"memory/stores/#store-selection-guide","title":"Store Selection Guide","text":""},{"location":"memory/stores/#choose-sqlite-when","title":"Choose SQLite when:","text":"<ul> <li>Simple deployment without external services</li> <li>Development and testing</li> <li>Small to medium memory collections</li> <li>Full-text search is sufficient</li> </ul>"},{"location":"memory/stores/#choose-chromadb-when","title":"Choose ChromaDB when:","text":"<ul> <li>Need semantic search without server setup</li> <li>Embedded vector database requirement</li> <li>Getting started with vector search</li> </ul>"},{"location":"memory/stores/#choose-qdrant-when","title":"Choose Qdrant when:","text":"<ul> <li>High-performance vector search required</li> <li>Large-scale deployments</li> <li>Need payload filtering</li> <li>Production workloads</li> </ul>"},{"location":"memory/stores/#choose-opensearch-when","title":"Choose OpenSearch when:","text":"<ul> <li>Need both vector and full-text search</li> <li>Enterprise requirements</li> <li>Distributed scaling needed</li> <li>Complex filtering and aggregations</li> </ul>"},{"location":"memory/stores/#choose-neo4j-when","title":"Choose Neo4j when:","text":"<ul> <li>Entity relationships are important</li> <li>Need graph traversal</li> <li>Knowledge graph use cases</li> <li>Relationship-based reasoning</li> </ul>"},{"location":"memory/types/","title":"Memory Types","text":"<p>Different types of memories for different purposes.</p>"},{"location":"memory/types/#available-types","title":"Available Types","text":"<pre><code>from src.memory.manager import MemoryType\n\nMemoryType.CONVERSATION     # Chat history\nMemoryType.ENTITY_FACT      # Facts about entities\nMemoryType.SCHEMA           # Database schema\nMemoryType.QUERY_PATTERN    # Successful SQL patterns\nMemoryType.ERROR_PATTERN    # Error patterns to avoid\nMemoryType.USER_PREFERENCE  # User preferences\nMemoryType.SEMANTIC         # General knowledge\n</code></pre>"},{"location":"memory/types/#usage-examples","title":"Usage Examples","text":""},{"location":"memory/types/#query-pattern","title":"Query Pattern","text":"<pre><code>await memory.add(\n    content=\"SELECT COUNT(*) FROM users WHERE active = true\",\n    memory_type=MemoryType.QUERY_PATTERN,\n    metadata={\"question\": \"active users\", \"success\": True},\n)\n</code></pre>"},{"location":"memory/types/#schema","title":"Schema","text":"<pre><code>await memory.add(\n    content=\"users: id, name, email, created_at\",\n    memory_type=MemoryType.SCHEMA,\n    metadata={\"table\": \"users\"},\n)\n</code></pre>"},{"location":"memory/types/#error-pattern","title":"Error Pattern","text":"<pre><code>await memory.add(\n    content=\"LIMIT doesn't work in MSSQL, use TOP\",\n    memory_type=MemoryType.ERROR_PATTERN,\n    metadata={\"dialect\": \"mssql\"},\n)\n</code></pre>"}]}